{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to EarthStat","text":"<p>A Python package for efficiently generating statistical datasets from raster data for spatial units.</p> <ul> <li>GitHub repo: https://github.com/AbdelrahmanAmr3/earthstat</li> <li>Documentation: https://abdelrahmanamr3.github.io/earthstat</li> <li>PyPI: https://pypi.org/project/earthstat</li> <li>Free software: MIT license</li> </ul> <p>EarthStat's Library Workflows's Notebooks:</p> <ul> <li> <p>Main Workflow: Google Colab, Binder</p> </li> <li> <p>xEearthStat Workflow: Google Colab, Binder</p> </li> </ul>"},{"location":"#introduction","title":"Introduction","text":"<p>Inspired by my engagement with the AgML community's \"Regional Crop Yield Forecasting\" challenge, I created a Python library designed to set benchmarks for Machine Learning (ML) models. The library presents an efficient workflow for extracting statistical information from big remote sensing and climate datasets. Currently, The library presents two workflows. First, for dealing with GeoTIFF files, as the main workflow of EarthStat. In addition, it presents a unique workflow for AgERA5 datasets, which gives the user the power to download a huge amount of different variables using CDS API, extended to extract and aggregate all downloaded data. EarthStat's workflows provide multiprocessing and GPU for parallel computation as an option. This library is particularly suited for creating statistical information datasets for ML models or for environmental analyses and monitoring.</p>"},{"location":"#earthstat-main-workflow","title":"EarthStat Main Workflow","text":"<p>This diagram illustrates the workflow of the geospatial data processing implemented in EarthStat from the initialized dataset to the created CSV file.</p> <p></p>"},{"location":"#earthstat-main-workflow-features","title":"EarthStat Main Workflow Features","text":"<p>EarthStat revolutionizes the extraction of statistical information from geographic data, offering a seamless workflow for effective data management:</p> <ul> <li> <p>Data Initialization &amp; Geo-metadata Readability: Streamlines the incorporation of datasets into EarthStat workflow, and getting insights of vital geo-metadata for data (Raster, Mask, Shapefile).</p> </li> <li> <p>netCDF Conversion: Seamlessly integrates netCDF files into the workflow, converting them effortlessly into GeoTIFF format.</p> </li> <li> <p>Data Compatibility Assurance: Simplifies ensuring data compatibility, swiftly identifying and addressing geo data discrepancies among initialized data (Raster, Mask, Shapefile).</p> </li> <li> <p>Automated Resolution of Compatibility Issues: EarthStat resolves compatibility concerns, employing automatic resampling or reprojecting techniques for masks, and appropriate projection adjustments for shapefiles.</p> </li> <li> <p>Targeted Region Selection: Easily filter the shapefile to the targeted region.</p> </li> <li> <p>Data Clipping: Allows for clip raster data to specific shapefile boundaries.</p> </li> <li> <p>Advanced Statistical Data Extraction: Offers a variety of statistical aggregation methods.</p> </li> <li> <p>Efficient Parallel Processing: Leverages the power of multiprocessing, significantly accelerating data processing across extensive datasets for quicker, more efficient computation.</p> </li> </ul>"},{"location":"#xearthstat-workflow-for-agera5","title":"xEarthStat Workflow For AgERA5","text":"<p>This diagram illustrates the workflow of xEearthStat for AgERA5 data processing.</p> <p></p>"},{"location":"#earthstat-main-workflow-features_1","title":"EarthStat Main Workflow Features","text":"<ul> <li>Unlimited AgERA5 Data Downloads: The EarthStat workflow enables users to bypass the limitations of the CDS server, allowing for the download of any quantity of data for the required variables.</li> <li>Fully Automated: This library is entirely automated and does not require any prior Python knowledge. Users simply need to select the variables for download and aggregation, specify the start and end years to determine the data volume, and define the shapefile containing the geometry objects.</li> <li>Parallel Computation: EarthStat workflow intelligently detects GPU availability to shift aggregation processes for parallel computation on the GPU. It also offers users the option to leverage available CPU cores for multiprocessing (Parallel Execution), enhancing I/O-bound tasks.</li> <li>Aggregated Data as CSV: Ultimately, the workflow provides users with a neatly organized CSV file, compiling all downloaded and aggregated variables.</li> </ul>"},{"location":"#xearthstat-workflow-performance-on-google-colab","title":"xEarthStat Workflow Performance on Google Colab","text":"<p>This table demonstrates the workflow's performance across various configurations, ranging from multiprocessing to GPU usage for parallel computation by using Google Colab.</p> Data Variables Number of Geo-Objects Dataset Processing Unit Time (Run: One Time) min Two year 7 EU (478) Dekadal CPU \u2013 Single Processing 13:56 - - - Dekadal CPU \u2013 Multiprocessing 13:48 - - - Daily CPU \u2013 Single Processing 1:20:43 - - - Daily CPU \u2013 Multiprocessing 1:18:32 - - - Dekadal T4 GPU \u2013 Single Processing 04:32 - - - Dekadal T4 GPU \u2013 Multiprocessing 04:12 - - - Daily T4 GPU \u2013 Single Processing 06:35 - - - Daily T4 GPU \u2013 Multiprocessing 06:14"},{"location":"#earthstat-python-library-improvements-roadmap","title":"EarthStat Python Library - Improvements Roadmap","text":""},{"location":"#earthstat-main-workflow_1","title":"EarthStat Main Workflow","text":""},{"location":"#data-processing-and-scenario-management-enhancements","title":"Data Processing and Scenario Management Enhancements","text":"<ul> <li>[x] offering more statistical options for aggregation.</li> <li>[ ] Introduce thresholding option for masks to refine data selection.</li> <li>[ ] Refactor Dataloader and Data Compatibility for no mask scenario.</li> </ul>"},{"location":"#automation-for-user-convenience","title":"Automation for User Convenience","text":"<ul> <li>[ ] Implement automatic detection of the lag between date ranges of predictor data.</li> <li>[ ] Automatically identify the column names for countries in the dataset.</li> <li>[ ] Enable users to specify date ranges for predictor data, improving data filtering capabilities.</li> </ul>"},{"location":"#xearthstat-workflow-for-agera5_1","title":"xEarthStat Workflow for AgERA5","text":"<ul> <li>[ ] Option to mask the AgERA5's data with mask</li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>To install EarthStat, ensure you have Python 3.9 or later installed. </p> <p>Install with pip: <pre><code>pip install earthstat\n</code></pre> Install with Conda: <pre><code>conda install conda-forge::earthstat\n</code></pre></p>"},{"location":"#earthstat-usage","title":"EarthStat Usage","text":"<ul> <li> <p>EarthStat Main Workflow</p> </li> <li> <p>xEearthStat for AgERA5 Workflow</p> </li> </ul>"},{"location":"analysis_aggregation/","title":"Extract Statistical Information","text":"<p>Insight into the <code>earthstat.analysis_aggregation</code> module, which facilitates advanced data aggregation methods for geospatial analysis, enhancing efficiency and accuracy.</p>"},{"location":"analysis_aggregation/#data-aggregation-techniques","title":"Data Aggregation Techniques","text":""},{"location":"analysis_aggregation/#aggregating-data-with-aggregate-process-function","title":"Aggregating Data with Aggregate Process Function","text":""},{"location":"analysis_aggregation/#earthstat.analysis_aggregation.aggregate_process.conAggregate","title":"<code>conAggregate(predictor_dir, shapefile_path, output_csv_path, mask_path=None, use_mask=False, invalid_values=None, calculation_mode='overall_mean', predictor_name='Value', all_touched=False)</code>","text":"<p>Aggregates raster values to polygons in a shapefile, optionally using a crop mask for weighted calculations.</p> <p>Parameters:</p> Name Type Description Default <code>predictor_dir</code> <code>str</code> <p>Directory containing raster datasets.</p> required <code>shapefile_path</code> <code>str</code> <p>Path to the shapefile with polygons for aggregation.</p> required <code>output_csv_path</code> <code>str</code> <p>Path where the aggregated output CSV will be saved.</p> required <code>crop_mask_path</code> <code>str</code> <p>Path to the crop mask raster, required if use_crop_mask is True.</p> required <code>use_crop_mask</code> <code>bool</code> <p>Whether to use the crop mask for weighted aggregation.</p> required <code>predictor_name</code> <code>str</code> <p>Column name for the aggregated values in the output CSV.</p> <code>'Value'</code> <p>Exceptions:</p> Type Description <code>ValueError</code> <p>If use_crop_mask is True but crop_mask_path is not provided.</p> <p>Aggregates values from each raster within the specified directory to each polygon in the shapefile, writing the results to a CSV file. If a crop mask is used, values are aggregated using weights from the mask; otherwise, simple averaging is applied.</p> Source code in <code>earthstat/analysis_aggregation/aggregate_process.py</code> <pre><code>def conAggregate(\n\n        predictor_dir,\n        shapefile_path,\n        output_csv_path,\n        mask_path=None,\n        use_mask=False,\n        invalid_values=None,\n        calculation_mode=\"overall_mean\",\n        predictor_name=\"Value\",\n        all_touched=False\n):\n    \"\"\"\n    Aggregates raster values to polygons in a shapefile, optionally using a crop mask for weighted calculations.\n\n    Args:\n        predictor_dir (str): Directory containing raster datasets.\n        shapefile_path (str): Path to the shapefile with polygons for aggregation.\n        output_csv_path (str): Path where the aggregated output CSV will be saved.\n        crop_mask_path (str, optional): Path to the crop mask raster, required if use_crop_mask is True.\n        use_crop_mask (bool): Whether to use the crop mask for weighted aggregation.\n        predictor_name (str): Column name for the aggregated values in the output CSV.\n\n    Raises:\n        ValueError: If use_crop_mask is True but crop_mask_path is not provided.\n\n    Aggregates values from each raster within the specified directory to each polygon in the shapefile,\n    writing the results to a CSV file. If a crop mask is used, values are aggregated using weights from\n    the mask; otherwise, simple averaging is applied.\n    \"\"\"\n    predictor_paths = loadTiff(predictor_dir)\n    data_list = []\n\n    shape_file = gpd.read_file(shapefile_path)\n\n    if use_mask and not mask_path:\n        raise ValueError(\"Mask path must be provided if use_mask is True.\")\n\n    for raster_path in tqdm(predictor_paths, desc=\"Processing rasters\", unit=\"raster\"):\n\n        # Directly call the processing function for each raster\n        data = process_and_aggregate_raster(\n\n            raster_path,\n            shape_file,\n            invalid_values,\n            use_mask,\n            mask_path,\n            calculation_mode,\n            predictor_name,\n            all_touched\n        )\n\n        data_list.extend(data)\n\n    df = pd.DataFrame(data_list)\n    df[predictor_name] = df[predictor_name].round(3)\n    df.to_csv(output_csv_path, index=False)\n</code></pre>"},{"location":"analysis_aggregation/#earthstat.analysis_aggregation.aggregate_process.process_and_aggregate_raster","title":"<code>process_and_aggregate_raster(raster_path, shape_file, invalid_values=None, use_mask=False, mask_path=None, calculation_mode='overall_mean', predictor_name='Value', all_touched=False)</code>","text":"<p>Processes a single raster for aggregation into shapefile geometries.</p> <p>Parameters:</p> Name Type Description Default <code>raster_path</code> <code>str</code> <p>Path to the raster file.</p> required <code>shape_file</code> <code>GeoDataFrame</code> <p>Loaded shapefile for geometries.</p> required <code>invalid_values</code> <code>list</code> <p>Values to consider as invalid in raster.</p> <code>None</code> <code>use_mask</code> <code>bool</code> <p>If True, uses an additional mask for calculations.</p> <code>False</code> <code>mask_path</code> <code>str</code> <p>Path to the mask file, required if use_mask is True.</p> <code>None</code> <code>calculation_mode</code> <code>str</code> <p>Mode of calculation ('overall_mean', 'weighted_mean', or 'filtered_mean').</p> <code>'overall_mean'</code> <code>predictor_name</code> <code>str</code> <p>Column name for the output data.</p> <code>'Value'</code> <code>all_touched</code> <code>bool</code> <p>Consider all pixels that touch geometry for masking.</p> <code>False</code> <p>Returns:</p> Type Description <code>list</code> <p>Aggregated data for each geometry in the shapefile.</p> Source code in <code>earthstat/analysis_aggregation/aggregate_process.py</code> <pre><code>def process_and_aggregate_raster(\n\n    raster_path,\n    shape_file,\n    invalid_values=None,\n    use_mask=False,\n    mask_path=None,\n    calculation_mode=\"overall_mean\",\n    predictor_name=\"Value\",\n    all_touched=False\n):\n    \"\"\"\n    Processes a single raster for aggregation into shapefile geometries.\n\n    Args:\n        raster_path (str): Path to the raster file.\n        shape_file (GeoDataFrame): Loaded shapefile for geometries.\n        invalid_values (list, optional): Values to consider as invalid in raster.\n        use_mask (bool): If True, uses an additional mask for calculations.\n        mask_path (str, optional): Path to the mask file, required if use_mask is True.\n        calculation_mode (str): Mode of calculation ('overall_mean', 'weighted_mean', or 'filtered_mean').\n        predictor_name (str): Column name for the output data.\n        all_touched (bool): Consider all pixels that touch geometry for masking.\n\n    Returns:\n        list: Aggregated data for each geometry in the shapefile.\n    \"\"\"\n\n    file_name = os.path.basename(raster_path)\n    date_str = extractDateFromFilename(file_name)\n    aggregated_data = []\n\n    with rasterio.open(raster_path) as src:\n        no_data_value = src.nodata\n        geoms = [mapping(shape) for shape in shape_file.geometry]\n\n        mask_no_data_value = None\n        mask_src = None\n\n        if use_mask and mask_path:\n            mask_src = rasterio.open(mask_path)\n            mask_no_data_value = mask_src.nodata\n\n        for index, geom in enumerate(geoms):\n            geom_mask, geom_transform = mask(\n                src, [geom], crop=True, all_touched=all_touched)\n            geom_mask = geom_mask.astype('float32')\n            geom_mask[geom_mask == no_data_value] = np.nan\n\n            if invalid_values:\n                for invalid_value in invalid_values:\n                    geom_mask[geom_mask == invalid_value] = np.nan\n\n            if use_mask and mask_path and mask_src:\n                crop_mask, _ = mask(\n                    mask_src, [geom], crop=True, all_touched=all_touched)\n\n                if calculation_mode == \"weighted_mean\":\n                    valid_mask = (crop_mask[0] != mask_no_data_value)\n                    valid_data = geom_mask[0][valid_mask]\n                    valid_weights = crop_mask[0][valid_mask]\n                    mean_value = np.nansum(valid_data * valid_weights) / np.nansum(\n                        valid_weights) if np.nansum(valid_weights) &gt; 0 else np.nan\n\n                elif calculation_mode == \"filtered_mean\":\n                    valid_mask = (crop_mask[0] != mask_no_data_value)\n                    masked_data = geom_mask[0][valid_mask]\n                    mean_value = np.nanmean(masked_data) if np.nansum(\n                        masked_data) &gt; 0 else np.nan\n\n            elif calculation_mode == \"overall_mean\" or not use_mask:\n                mean_value = np.nanmean(geom_mask)\n\n            new_row = {col: shape_file.iloc[index][col]\n                       for col in shape_file.columns if col != 'geometry'}\n            new_row.update({'date': date_str, predictor_name: mean_value})\n            aggregated_data.append(new_row)\n\n        if mask_src:\n            mask_src.close()\n\n    return aggregated_data\n</code></pre>"},{"location":"analysis_aggregation/#efficient-aggregation-via-parallel-clip-aggregate-function","title":"Efficient Aggregation via Parallel Clip Aggregate Function","text":""},{"location":"analysis_aggregation/#earthstat.analysis_aggregation.parallel_clip_aggregate.parallelAggregate","title":"<code>parallelAggregate(predictor_dir, shapefile_path, output_csv_path, mask_path=None, use_mask=False, invalid_values=None, calculation_mode='overall_mean', predictor_name='Value', all_touched=False, max_workers=None)</code>","text":"<p>Aggregates raster data from a directory in parallel into shapefile geometries, optionally using a mask.</p> <p>Parameters:</p> Name Type Description Default <code>predictor_dir</code> <code>str</code> <p>Directory containing raster datasets.</p> required <code>shapefile_path</code> <code>str</code> <p>Path to the shapefile.</p> required <code>output_csv_path</code> <code>str</code> <p>Path to save the aggregated CSV.</p> required <code>mask_path</code> <code>str</code> <p>Path to the mask file, required if use_mask is True.</p> <code>None</code> <code>use_mask</code> <code>bool</code> <p>Use a mask for the aggregation process.</p> <code>False</code> <code>invalid_values</code> <code>list</code> <p>List of values to treat as invalid in the raster data.</p> <code>None</code> <code>calculation_mode</code> <code>str</code> <p>Determines how values are aggregated ('overall_mean', 'weighted_mean', or 'filtered_mean').</p> <code>'overall_mean'</code> <code>predictor_name</code> <code>str</code> <p>Name for the output predictor column.</p> <code>'Value'</code> <code>all_touched</code> <code>bool</code> <p>Include all pixels touching geometry in the aggregation.</p> <code>False</code> <p>Exceptions:</p> Type Description <code>ValueError</code> <p>If use_mask is True and mask_path is not provided.</p> <p>Returns a CSV with aggregated data per shapefile geometry. Utilizes multiprocessing for efficiency.</p> Source code in <code>earthstat/analysis_aggregation/parallel_clip_aggregate.py</code> <pre><code>def parallelAggregate(\n    predictor_dir,\n    shapefile_path,\n    output_csv_path,\n    mask_path=None,\n    use_mask=False,\n    invalid_values=None,\n    calculation_mode=\"overall_mean\",\n    predictor_name=\"Value\",\n    all_touched=False,\n    max_workers=None\n):\n    \"\"\"\n    Aggregates raster data from a directory in parallel into shapefile geometries, optionally using a mask.\n\n    Args:\n        predictor_dir (str): Directory containing raster datasets.\n        shapefile_path (str): Path to the shapefile.\n        output_csv_path (str): Path to save the aggregated CSV.\n        mask_path (str, optional): Path to the mask file, required if use_mask is True.\n        use_mask (bool): Use a mask for the aggregation process.\n        invalid_values (list, optional): List of values to treat as invalid in the raster data.\n        calculation_mode (str): Determines how values are aggregated ('overall_mean', 'weighted_mean', or 'filtered_mean').\n        predictor_name (str): Name for the output predictor column.\n        all_touched (bool): Include all pixels touching geometry in the aggregation.\n\n    Raises:\n        ValueError: If use_mask is True and mask_path is not provided.\n\n    Returns a CSV with aggregated data per shapefile geometry. Utilizes multiprocessing for efficiency.\n    \"\"\"\n    if not max_workers:\n        max_workers = os.cpu_count() - 1 if os.cpu_count() &gt; 1 else 1\n\n    predictor_paths = loadTiff(predictor_dir)\n    data_list = []\n\n    shape_file = gpd.read_file(shapefile_path)\n\n    if use_mask and not mask_path:\n        raise ValueError(\"Mask path must be provided if use_mask is True.\")\n\n    # Prepare arguments for starmap\n    task_args = [\n        (\n            raster_path,\n            shape_file,\n            invalid_values,\n            use_mask,\n            mask_path,\n            calculation_mode,\n            predictor_name,\n            all_touched\n        ) for raster_path in predictor_paths\n    ]\n\n    # with multiprocessing.Pool(processes=max_workers) as pool:\n    with Pool(processes=max_workers) as pool:\n        results = []\n        # Wrap pool.imap or pool.imap_unordered for a real-time tqdm progress bar\n        # results = list(tqdm(pool.starmap(process_and_aggregate_raster, task_args), total=len(\n        #     task_args), desc=\"Processing rasters\", unit=\"raster\"))\n\n        # for result in results:\n        #     data_list.extend(result)\n        for result in tqdm(pool.imap(process_wrapper, task_args, chunksize=1), total=len(task_args), desc=\"Processing rasters\", unit=\"raster\"):\n            results.append(result)\n            data_list.extend(result)\n\n    df = pd.DataFrame(data_list)\n    df[predictor_name] = df[predictor_name].round(3)\n    df.to_csv(output_csv_path, index=False)\n</code></pre>"},{"location":"analysis_aggregation/#earthstat.analysis_aggregation.parallel_clip_aggregate.process_and_aggregate_raster","title":"<code>process_and_aggregate_raster(raster_path, shape_file, invalid_values=None, use_mask=False, mask_path=None, calculation_mode='overall_mean', predictor_name='Value', all_touched=False)</code>","text":"<p>Processes a single raster for aggregation into shapefile geometries.</p> <p>Parameters:</p> Name Type Description Default <code>raster_path</code> <code>str</code> <p>Path to the raster file.</p> required <code>shape_file</code> <code>GeoDataFrame</code> <p>Loaded shapefile for geometries.</p> required <code>invalid_values</code> <code>list</code> <p>Values to consider as invalid in raster.</p> <code>None</code> <code>use_mask</code> <code>bool</code> <p>If True, uses an additional mask for calculations.</p> <code>False</code> <code>mask_path</code> <code>str</code> <p>Path to the mask file, required if use_mask is True.</p> <code>None</code> <code>calculation_mode</code> <code>str</code> <p>Mode of calculation ('overall_mean', 'weighted_mean', or 'filtered_mean').</p> <code>'overall_mean'</code> <code>predictor_name</code> <code>str</code> <p>Column name for the output data.</p> <code>'Value'</code> <code>all_touched</code> <code>bool</code> <p>Consider all pixels that touch geometry for masking.</p> <code>False</code> <p>Returns:</p> Type Description <code>list</code> <p>Aggregated data for each geometry in the shapefile.</p> Source code in <code>earthstat/analysis_aggregation/parallel_clip_aggregate.py</code> <pre><code>def process_and_aggregate_raster(\n\n        raster_path,\n        shape_file,\n        invalid_values=None,\n        use_mask=False,\n        mask_path=None,\n        calculation_mode=\"overall_mean\",\n        predictor_name=\"Value\",\n        all_touched=False\n):\n    \"\"\"\n    Processes a single raster for aggregation into shapefile geometries.\n\n    Args:\n        raster_path (str): Path to the raster file.\n        shape_file (GeoDataFrame): Loaded shapefile for geometries.\n        invalid_values (list, optional): Values to consider as invalid in raster.\n        use_mask (bool): If True, uses an additional mask for calculations.\n        mask_path (str, optional): Path to the mask file, required if use_mask is True.\n        calculation_mode (str): Mode of calculation ('overall_mean', 'weighted_mean', or 'filtered_mean').\n        predictor_name (str): Column name for the output data.\n        all_touched (bool): Consider all pixels that touch geometry for masking.\n\n    Returns:\n        list: Aggregated data for each geometry in the shapefile.\n    \"\"\"\n    file_name = os.path.basename(raster_path)\n    date_str = extractDateFromFilename(file_name)\n    aggregated_data = []\n\n    with rasterio.open(raster_path) as src:\n        no_data_value = src.nodata\n        geoms = [mapping(shape) for shape in shape_file.geometry]\n\n        mask_no_data_value = None\n        mask_src = None\n\n        if use_mask and mask_path:\n            mask_src = rasterio.open(mask_path)\n            mask_no_data_value = mask_src.nodata\n\n        for index, geom in enumerate(geoms):\n            geom_mask, geom_transform = mask(\n                src, [geom], crop=True, all_touched=all_touched)\n            geom_mask = geom_mask.astype('float32')\n            geom_mask[geom_mask == no_data_value] = np.nan\n\n            if invalid_values:\n                for invalid_value in invalid_values:\n                    geom_mask[geom_mask == invalid_value] = np.nan\n\n            if use_mask and mask_path and mask_src:\n                crop_mask, _ = mask(\n                    mask_src, [geom], crop=True, all_touched=all_touched)\n\n                if calculation_mode == \"weighted_mean\":\n                    valid_mask = (crop_mask[0] != mask_no_data_value)\n                    valid_data = geom_mask[0][valid_mask]\n                    valid_weights = crop_mask[0][valid_mask]\n                    mean_value = np.nansum(valid_data * valid_weights) / np.nansum(\n                        valid_weights) if np.nansum(valid_weights) &gt; 0 else np.nan\n\n                elif calculation_mode == \"filtered_mean\":\n                    valid_mask = (crop_mask[0] != mask_no_data_value)\n                    masked_data = geom_mask[0][valid_mask]\n                    mean_value = np.nanmean(masked_data) if np.nansum(\n                        masked_data) &gt; 0 else np.nan\n\n            elif calculation_mode == \"overall_mean\" or not use_mask:\n                mean_value = np.nanmean(geom_mask)\n\n            new_row = {col: shape_file.iloc[index][col]\n                       for col in shape_file.columns if col != 'geometry'}\n            new_row.update({'date': date_str, predictor_name: mean_value})\n            aggregated_data.append(new_row)\n\n        if mask_src:\n            mask_src.close()\n\n    return aggregated_data\n</code></pre>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#v001-date","title":"v0.0.1 - Date","text":"<p>Improvement:</p> <ul> <li>TBD</li> </ul> <p>New Features:</p> <ul> <li>TBD</li> </ul>"},{"location":"contributing/","title":"Contributing","text":"<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.</p> <p>You can contribute in many ways:</p>"},{"location":"contributing/#types-of-contributions","title":"Types of Contributions","text":""},{"location":"contributing/#report-bugs","title":"Report Bugs","text":"<p>Report bugs at https://github.com/AbdelrahmanAmr3/earthstat/issues.</p> <p>If you are reporting a bug, please include:</p> <ul> <li>Your operating system name and version.</li> <li>Any details about your local setup that might be helpful in troubleshooting.</li> <li>Detailed steps to reproduce the bug.</li> </ul>"},{"location":"contributing/#fix-bugs","title":"Fix Bugs","text":"<p>Look through the GitHub issues for bugs. Anything tagged with <code>bug</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#implement-features","title":"Implement Features","text":"<p>Look through the GitHub issues for features. Anything tagged with <code>enhancement</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#write-documentation","title":"Write Documentation","text":"<p>EarthStat could always use more documentation, whether as part of the official EarthStat docs, in docstrings, or even on the web in blog posts, articles, and such.</p>"},{"location":"contributing/#submit-feedback","title":"Submit Feedback","text":"<p>The best way to send feedback is to file an issue at https://github.com/AbdelrahmanAmr3/earthstat/issues.</p> <p>If you are proposing a feature:</p> <ul> <li>Explain in detail how it would work.</li> <li>Keep the scope as narrow as possible, to make it easier to implement.</li> <li>Remember that this is a volunteer-driven project, and that contributions are welcome :)</li> </ul>"},{"location":"contributing/#get-started","title":"Get Started!","text":"<p>Ready to contribute? Here's how to set up earthstat for local development.</p> <ol> <li> <p>Fork the earthstat repo on GitHub.</p> </li> <li> <p>Clone your fork locally:</p> <pre><code>$ git clone git@github.com:your_name_here/earthstat.git\n</code></pre> </li> <li> <p>Install your local copy into a virtualenv. Assuming you have     virtualenvwrapper installed, this is how you set up your fork for     local development:</p> <pre><code>$ mkvirtualenv earthstat\n$ cd earthstat/\n$ python setup.py develop\n</code></pre> </li> <li> <p>Create a branch for local development:</p> <pre><code>$ git checkout -b name-of-your-bugfix-or-feature\n</code></pre> <p>Now you can make your changes locally.</p> </li> <li> <p>When you're done making changes, check that your changes pass flake8     and the tests, including testing other Python versions with tox:</p> <pre><code>$ flake8 earthstat tests\n$ python setup.py test or pytest\n$ tox\n</code></pre> <p>To get flake8 and tox, just pip install them into your virtualenv.</p> </li> <li> <p>Commit your changes and push your branch to GitHub:</p> <pre><code>$ git add .\n$ git commit -m \"Your detailed description of your changes.\"\n$ git push origin name-of-your-bugfix-or-feature\n</code></pre> </li> <li> <p>Submit a pull request through the GitHub website.</p> </li> </ol>"},{"location":"contributing/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<p>Before you submit a pull request, check that it meets these guidelines:</p> <ol> <li>The pull request should include tests.</li> <li>If the pull request adds functionality, the docs should be updated.     Put your new functionality into a function with a docstring, and add     the feature to the list in README.rst.</li> <li>The pull request should work for Python 3.8 and later, and     for PyPy. Check https://github.com/AbdelrahmanAmr3/earthstat/pull_requests and make sure that the tests pass for all     supported Python versions.</li> </ol>"},{"location":"data_compatibility/","title":"Data Compatibility","text":"<p>Explore the <code>earthstat.data_compatibility</code> module designed to ensure and enhance compatibility across different data sets and formats used in geospatial analysis.</p>"},{"location":"data_compatibility/#ensuring-data-compatibility","title":"Ensuring Data Compatibility","text":""},{"location":"data_compatibility/#checking-data-compatibility","title":"Checking Data Compatibility","text":""},{"location":"data_compatibility/#earthstat.data_compatibility.data_compatibility.checkDataCompatibility","title":"<code>checkDataCompatibility(raster_data_path, mask_path, shapefile_path)</code>","text":"<p>Checks spatial resolution and CRS compatibility among a raster dataset, mask, and shapefile.</p> <p>Determines if the mask needs resampling to match the raster dataset's resolution or if the shapefile needs reprojecting to match the raster's CRS. Identifies overall data compatibility.</p> <p>Parameters:</p> Name Type Description Default <code>raster_data_path</code> <code>str</code> <p>Path to the raster dataset file.</p> required <code>mask_path</code> <code>str</code> <p>Path to the mask file.</p> required <code>shapefile_path</code> <code>str</code> <p>Path to the shapefile.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary indicating required actions (resample_mask, reproject_shapefile) and        overall compatibility (is_compatible).</p> <p>Exceptions:</p> Type Description <code>CRSError</code> <p>If there's an issue reading the CRS data from any file.</p> <code>Exception</code> <p>For general errors encountered during processing.</p> Source code in <code>earthstat/data_compatibility/data_compatibility.py</code> <pre><code>def checkDataCompatibility(raster_data_path, mask_path, shapefile_path):\n    \"\"\"\n    Checks spatial resolution and CRS compatibility among a raster dataset, mask, and shapefile.\n\n    Determines if the mask needs resampling to match the raster dataset's resolution or if the shapefile\n    needs reprojecting to match the raster's CRS. Identifies overall data compatibility.\n\n    Args:\n        raster_data_path (str): Path to the raster dataset file.\n        mask_path (str): Path to the mask file.\n        shapefile_path (str): Path to the shapefile.\n\n    Returns:\n        dict: A dictionary indicating required actions (resample_mask, reproject_shapefile) and \n              overall compatibility (is_compatible).\n\n    Raises:\n        CRSError: If there's an issue reading the CRS data from any file.\n        Exception: For general errors encountered during processing.\n    \"\"\"\n    actions = {'resample_mask': False,\n               'reproject_shapefile': False, 'is_compatible': True}\n\n    try:\n        with rasterio.open(mask_path) as mask, rasterio.open(raster_data_path) as raster_data:\n            checkPixelSize(mask, raster_data)\n            if mask.res != raster_data.res:\n                actions['resample_mask'] = True\n                actions['is_compatible'] = False\n\n            mask_crs_name = CRS(mask.crs).name\n            raster_data_crs_name = CRS(raster_data.crs).name\n            checkProjection(mask_crs_name, raster_data_crs_name,\n                            \"mask\", \"predictor\")\n            if mask_crs_name != raster_data_crs_name:\n                actions['is_compatible'] = False\n\n        shapefile = gpd.read_file(shapefile_path)\n        shapefile_crs_name = CRS(shapefile.crs).name\n        checkProjection(raster_data_crs_name, shapefile_crs_name,\n                        \"raster data\", \"shapefile\")\n        if raster_data_crs_name != shapefile_crs_name:\n            actions['reproject_shapefile'] = True\n            actions['is_compatible'] = False\n\n        return actions\n    except CRSError as e:\n        print(f\"Error reading CRS data: {e}\")\n        return actions\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        return actions\n</code></pre>"},{"location":"data_compatibility/#resolving-compatibility-issues","title":"Resolving Compatibility Issues","text":""},{"location":"data_compatibility/#addressing-and-fixing-data-compatibility-issues","title":"Addressing and Fixing Data Compatibility Issues","text":""},{"location":"data_compatibility/#earthstat.data_compatibility.process_comp_issues.processCompatibilityIssues","title":"<code>processCompatibilityIssues(actions, mask_path, predictor_data_path, shapefile_path, rescale_factor=None, resampling_method='bilinear')</code>","text":"<p>Processes identified compatibility issues by resampling masks and/or reprojection of shapefiles to match a predictor dataset's specifications.</p> <p>Parameters:</p> Name Type Description Default <code>actions</code> <code>dict</code> <p>A dictionary indicating which compatibility actions are required.</p> required <code>mask_path</code> <code>str</code> <p>Path to the original mask file.</p> required <code>predictor_data_path</code> <code>str</code> <p>Path to the raster dataset used as the predictor.</p> required <code>shapefile_path</code> <code>str</code> <p>Path to the original shapefile.</p> required <code>rescale_factor</code> <code>tuple</code> <p>Min and max values for rescaling the mask data.</p> <code>None</code> <code>resampling_method</code> <code>str</code> <p>Method to use for resampling ('bilinear' by default).</p> <code>'bilinear'</code> <p>Returns:</p> Type Description <code>dict</code> <p>Updated paths for the processed mask and shapefile.</p> <p>Performs resampling of the mask and reprojection of the shapefile based on the actions specified in the <code>actions</code> dictionary. Returns updated file paths for these processed files.</p> Source code in <code>earthstat/data_compatibility/process_comp_issues.py</code> <pre><code>def processCompatibilityIssues(actions, mask_path, predictor_data_path, shapefile_path, rescale_factor=None, resampling_method=\"bilinear\"):\n    \"\"\"\n    Processes identified compatibility issues by resampling masks and/or reprojection of shapefiles\n    to match a predictor dataset's specifications.\n\n    Args:\n        actions (dict): A dictionary indicating which compatibility actions are required.\n        mask_path (str): Path to the original mask file.\n        predictor_data_path (str): Path to the raster dataset used as the predictor.\n        shapefile_path (str): Path to the original shapefile.\n        rescale_factor (tuple, optional): Min and max values for rescaling the mask data.\n        resampling_method (str): Method to use for resampling ('bilinear' by default).\n\n    Returns:\n        dict: Updated paths for the processed mask and shapefile.\n\n    Performs resampling of the mask and reprojection of the shapefile based on the actions specified\n    in the `actions` dictionary. Returns updated file paths for these processed files.\n    \"\"\"\n    updated_paths = {\n        'crop_mask': mask_path,\n        'shapefile': shapefile_path\n    }\n\n    if not actions['is_compatible']:\n        if actions['resample_mask']:\n            updated_paths['crop_mask'] = rescaleResampleMask(mask_path,\n                                                             predictor_data_path,\n                                                             scale_factor=rescale_factor,\n                                                             resampling_method=resampling_method)\n\n        if actions['reproject_shapefile']:\n            print(\"\\nReprojecting shapefile...\")\n            updated_paths['shapefile'] = reprojectShapefileToRaster(\n                predictor_data_path, shapefile_path)\n\n    else:\n        print(\"No compatibility issues detected. Proceeding without resampling or reprojection.\")\n\n    return updated_paths\n</code></pre>"},{"location":"data_converter/","title":"Data Format Conversion Tools","text":"<p>Introduction to the <code>earthstat.data_converter</code> module, which provides efficient solutions for converting between different geospatial data formats, catering to a variety of analysis needs.</p>"},{"location":"data_converter/#file-format-conversions","title":"File Format Conversions","text":""},{"location":"data_converter/#converting-netcdf-to-geotiff-format","title":"Converting NetCDF to GeoTIFF Format","text":""},{"location":"data_converter/#earthstat.data_converter.netcdf_to_tiff.convertToTIFF","title":"<code>convertToTIFF(input_dir)</code>","text":"<p>Converts all NetCDF files in a directory to TIFF format and saves them in a subdirectory.</p> <p>Parameters:</p> Name Type Description Default <code>input_dir</code> <code>str</code> <p>Directory containing NetCDF files to be converted.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Path to the output directory containing the converted TIFF files.</p> <p>Utilizes multiprocessing for efficiency. Creates a 'predictor_tiff' subdirectory for outputs.</p> Source code in <code>earthstat/data_converter/netcdf_to_tiff.py</code> <pre><code>def convertToTIFF(input_dir):\n    \"\"\"\n    Converts all NetCDF files in a directory to TIFF format and saves them in a subdirectory.\n\n    Args:\n        input_dir (str): Directory containing NetCDF files to be converted.\n\n    Returns:\n        str: Path to the output directory containing the converted TIFF files.\n\n    Utilizes multiprocessing for efficiency. Creates a 'predictor_tiff' subdirectory for outputs.\n    \"\"\"\n    nc_files = glob.glob(os.path.join(input_dir, '*.nc'))\n    output_dir = os.path.join(input_dir, 'predictor_tiff')\n    os.makedirs(output_dir, exist_ok=True)\n\n    with ProcessPoolExecutor() as executor:\n        futures = [executor.submit(netCDFToTiff, file, output_dir)\n                   for file in nc_files]\n        for _ in tqdm(as_completed(futures), total=len(futures), desc=\"Converting Files\"):\n            pass\n\n    return output_dir\n</code></pre>"},{"location":"data_converter/#earthstat.data_converter.netcdf_to_tiff.netCDFToTiff","title":"<code>netCDFToTiff(netcdf_file, output_dir, default_crs='EPSG:4326')</code>","text":"<p>Converts a NetCDF file to TIFF format using a specified or default CRS.</p> <p>Parameters:</p> Name Type Description Default <code>netcdf_file</code> <code>str</code> <p>Path to the NetCDF file to be converted.</p> required <code>output_dir</code> <code>str</code> <p>Directory where the converted TIFF file will be saved.</p> required <code>default_crs</code> <code>str</code> <p>Default Coordinate Reference System in EPSG code. Defaults to 'EPSG:4326'.</p> <code>'EPSG:4326'</code> <p>Converts NetCDF to TIFF and applies LZW compression. Assumes NetCDF has geospatial data.</p> Source code in <code>earthstat/data_converter/netcdf_to_tiff.py</code> <pre><code>def netCDFToTiff(netcdf_file, output_dir, default_crs='EPSG:4326'):\n    \"\"\"\n    Converts a NetCDF file to TIFF format using a specified or default CRS.\n\n    Args:\n        netcdf_file (str): Path to the NetCDF file to be converted.\n        output_dir (str): Directory where the converted TIFF file will be saved.\n        default_crs (str): Default Coordinate Reference System in EPSG code. Defaults to 'EPSG:4326'.\n\n    Converts NetCDF to TIFF and applies LZW compression. Assumes NetCDF has geospatial data.\n    \"\"\"\n    output_file = os.path.join(output_dir, os.path.basename(\n        netcdf_file).replace(\".nc\", \".tif\"))\n\n    with rasterio.open(netcdf_file) as src:\n        data = src.read()\n        transform = src.transform\n        crs = src.crs\n        if crs is None:\n            crs = CRS.from_string(default_crs)\n        kwargs = src.profile.copy()\n        kwargs.update(\n            driver='GTiff',\n            height=src.height,\n            width=src.width,\n            count=data.shape[0],\n            dtype=data.dtype,\n            crs=crs,\n            transform=transform,\n            compress=\"lzw\"  # compression\n        )\n\n        with rasterio.open(output_file, 'w', **kwargs) as dst:\n            dst.write(data)\n</code></pre>"},{"location":"data_converter/#transforming-hdf5-to-geotiff-format","title":"Transforming HDF5 to GeoTIFF Format","text":""},{"location":"data_converter/#earthstat.data_converter.hdf5_to_tiff.hdf5ToGeoTIFF","title":"<code>hdf5ToGeoTIFF()</code>","text":"<p>Convert HDF5 to GeoTIFF.</p> Source code in <code>earthstat/data_converter/hdf5_to_tiff.py</code> <pre><code>def hdf5ToGeoTIFF():\n    \"\"\"\n    Convert HDF5 to GeoTIFF.\n\n    \"\"\"\n    pass\n</code></pre>"},{"location":"earthstat/","title":"earthstat module","text":""},{"location":"earthstat/#earthstat.earthstat.EarthStat","title":"<code> EarthStat        </code>","text":"<p>A class to manage and process geospatial data for EarthStat-compatible datasets.</p> <p>Attributes:</p> Name Type Description <code>predictor_name</code> <code>str</code> <p>Name of the predictor variable.</p> <code>predictor_paths</code> <code>list</code> <p>Paths to predictor raster files.</p> <code>predictor_dir</code> <code>str</code> <p>Directory containing predictor data.</p> <code>predictor_example</code> <code>str</code> <p>An example file from predictor data.</p> <code>mask_path</code> <code>str</code> <p>Path to the mask raster file.</p> <code>shapefile_path</code> <code>str</code> <p>Path to the shapefile.</p> <code>process_compatibility</code> <code>dict</code> <p>Results from compatibility check.</p> <code>use_crop_mask</code> <code>bool</code> <p>Whether to use a cropping mask in processing.</p> <code>predictory_meta,</code> <code>mask_meta, shapefile_meta (dict</code> <p>Metadata for respective data types.</p> <code>ROI</code> <code>GeoDataFrame</code> <p>Selected region of interest.</p> <code>clipped_dir</code> <code>str</code> <p>Directory containing clipped raster data.</p> <code>aggregated_csv</code> <code>str</code> <p>Path to the output aggregated CSV file.</p> Source code in <code>earthstat/earthstat.py</code> <pre><code>class EarthStat():\n    \"\"\"\n    A class to manage and process geospatial data for EarthStat-compatible datasets.\n\n    Attributes:\n        predictor_name (str): Name of the predictor variable.\n        predictor_paths (list): Paths to predictor raster files.\n        predictor_dir (str): Directory containing predictor data.\n        predictor_example (str): An example file from predictor data.\n        mask_path (str): Path to the mask raster file.\n        shapefile_path (str): Path to the shapefile.\n        process_compatibility (dict): Results from compatibility check.\n        use_crop_mask (bool): Whether to use a cropping mask in processing.\n        predictory_meta, mask_meta, shapefile_meta (dict): Metadata for respective data types.\n        ROI (GeoDataFrame): Selected region of interest.\n        clipped_dir (str): Directory containing clipped raster data.\n        aggregated_csv (str): Path to the output aggregated CSV file.\n    \"\"\"\n\n    def __init__(self, predictor_name):\n\n        self.predictor_name = predictor_name\n        self.predictor_paths = None\n        self.predictor_dir = None\n        self.predictor_example = None\n        self.mask_path = None\n        self.shapefile_path = None\n        self.process_compatibility = None\n        self.use_crop_mask = True  # IMPROVE: We have to change it relate the user\n\n        # Meta Data\n        self.predictory_meta = None\n        self.mask_meta = None\n        self.shapefile_meta = None\n\n        # Modified Data\n        self.ROI = None\n        self.clipped_dir = None\n\n        # Aggregated Data path\n        self.aggregated_csv = None\n\n    def initDataDir(self, data_dir):\n        \"\"\"\n        Initializes the directory containing predictor data, checks for data format, and optionally converts netCDF to TIFF.\n\n        Args:\n            data_dir (str): Path to the directory containing predictor data.\n        \"\"\"\n        has_tiff = any(file.endswith('.tif') for file in os.listdir(data_dir))\n\n        if has_tiff:\n            print(\"TIFF data found. Loading...\\n\")\n            # Proceed to load TIFF data without conversion\n            self.predictor_paths = loadTiff(data_dir)\n\n        else:\n            # If no TIFF files, check for netCDF files\n            has_netcdf = any(file.endswith('.nc')\n                             for file in os.listdir(data_dir))\n\n            if has_netcdf:\n                convert_choice = input(\n                    \"The data is in netCDF format. Do you want to convert it to TIFF? (y/n): \")\n\n                if convert_choice.lower() == 'y':\n\n                    # If user chooses to convert, convert the data to TIFF\n                    data_dir = convertToTIFF(data_dir)\n                    print(\"Data converted to TIFF successfully.\\n\")\n                    self.predictor_paths = loadTiff(data_dir)\n\n                else:\n\n                    print(\n                        \"Data will not be converted. EarthStat just works with TIFF data.\")\n                    return\n\n            else:\n                print(\"No netCDF or TIFF data found in the directory.\")\n                return\n\n        self.predictor_dir = data_dir\n        self.predictor_example = self.predictor_paths[0]\n        self.predictory_meta = predictorMeta(data_dir, self.predictor_name)\n        print(\"\\nPredictor Paths Initialized Correctly, Initialize The Mask's Path\")\n\n    def initMaskPath(self, mask_path):\n        \"\"\"\n        Initializes the path to the mask raster and extracts its metadata.\n\n        Args:\n            mask_path (str): Path to the mask raster file.\n        \"\"\"\n\n        self.mask_path = mask_path\n        # Function to identify mask information\n        self.mask_meta = maskSummary(self.mask_path)\n        print(\"\\nMask Initialized Correctly, Initialize The Shapefile\")\n\n    def initShapefilePath(self, shapefile_path):\n        \"\"\"\n        Initializes the path to the shapefile and extracts its metadata.\n\n        Args:\n            shapefile_path (str): Path to the shapefile.\n        \"\"\"\n\n        self.shapefile_path = shapefile_path\n        self.shapefile_meta = shapefileMeta(self.shapefile_path)\n\n        if self.mask_path and self.predictor_paths:\n            print(\n                \"\\nShapefile Initialized Correctly, You Can Check The Data Compatibility\")\n        else:\n            print(\n                \"\\nShapefile Initialized Correctly, But The Mask or Predictor Paths are not initialized\")\n\n    def DataCompatibility(self):\n        \"\"\"\n        Checks data compatibility among the predictor, mask, and shapefile based on spatial resolution and CRS.\n        \"\"\"\n\n        compatibility_result = checkDataCompatibility(\n\n            self.predictor_example,\n            self.mask_path,\n            self.shapefile_path\n\n        )\n\n        self.process_compatibility = compatibility_result\n\n        if self.process_compatibility['is_compatible']:\n            print(\"\\nCOMPATIBILITY CHECK PASSED: The data is compatible. \"\n                  \"No resolution or projection mismatches were detected.\")\n\n        else:\n            print(\"\\nCOMPATIBILITY ISSUE DETECTED: The data is not compatible \"\n                  \"based on the current checks.\")\n\n    def fixCompatibilityIssues(self, rescale_factor=None, resampling_method=\"bilinear\"):\n        \"\"\"\n        Attempts to fix any detected compatibility issues between the predictor, mask, and shapefile.\n\n        Args:\n            rescale_factor (tuple, optional): Min and max values for rescaling the mask data.\n            resampling_method (str): Method for resampling. Defaults to 'bilinear'.\n        \"\"\"\n\n        print(\"Checking for compatibility issues...\")\n\n        if not self.process_compatibility['is_compatible']:\n            print(\"Compatibility issues detected. Starting the fix process...\")\n\n            if self.process_compatibility['resample_mask']:\n                print(\n                    \"- Resampling the mask to match the raster's resolution and extent.\")\n            else:\n                print(\"- The mask does not require resampling.\")\n\n            if self.process_compatibility['reproject_shapefile']:\n                print(\n                    \"- Reprojecting the shapefile to match the raster's coordinate reference system.\")\n            else:\n                print(\"- The shapefile does not require reprojection.\")\n\n            updated_paths = processCompatibilityIssues(\n\n                self.process_compatibility,\n                self.mask_path,\n                self.predictor_example,\n                self.shapefile_path,\n                rescale_factor,\n                resampling_method\n\n            )\n\n            self.mask_path = updated_paths.get('crop_mask', self.mask_path)\n\n            self.shapefile_path = updated_paths.get(\n                'shapefile',\n                self.shapefile_path\n            )\n\n            if self.process_compatibility['resample_mask']:\n                print(\n                    f\"Mask resampled successfully. Updated mask path: [{self.mask_path}]\")\n\n            print(\"\\nRe-checking data compatibility after applying fixes...\\n\")\n\n            self.process_compatibility = checkDataCompatibility(\n\n                self.predictor_example,\n                self.mask_path,\n                self.shapefile_path\n            )\n\n            if self.process_compatibility['is_compatible']:\n                print(\n                    \"\\nAll compatibility issues have been resolved.\"\n                    \"Data is now compatible.\")\n\n            else:\n                print(\n                    \"Some compatibility issues could not be resolved\"\n                    \"automatically. Further manual intervention required.\")\n\n        else:\n            print(\n                \"No compatibility issues detected. Predictor, mask,\"\n                \"and shapefile are already compatible.\")\n\n    def selectRegionOfInterest(self, countries, country_column_name):\n        \"\"\"\n        Selects a region of interest (ROI) within the shapefile based on specified countries.\n\n        Args:\n            countries (list of str): Countries to include in the ROI.\n            country_column_name (str): Column name in the shapefile containing country names.\n        \"\"\"\n\n        self.ROI = extractROI(\n\n            self.shapefile_path,\n            countries,\n            country_column_name\n\n        )\n\n        if self.ROI:\n\n            print(\n                f\"Region of Interest (ROI) successfully selected based on \"\n                f\"the specified countries: {', '.join(countries)}.\")\n\n        else:\n            print(\"Failed to select the Region of Interest (ROI).\"\n                  \"Please check the country names and column name provided.\")\n\n    def clipPredictor(\n\n        self,\n        invalid_values=None\n\n    ):\n        \"\"\"\n        Clips predictor data to the selected region of interest or the entire shapefile.\n\n        Args:\n            invalid_values (list, optional): List of values to treat as invalid in the raster data.\n        \"\"\"\n\n        print(\"Clipping the predictor data...\")\n\n        if self.ROI:\n\n            self.clipped_dir = clipRaster(\n\n                self.predictor_paths,\n                self.ROI,\n                invalid_values=invalid_values\n\n            )\n\n            print(\"Clipping operation successful with the Region of Interest (ROI).\")\n\n        elif not self.ROI:\n\n            self.clipped_dir = clipRaster(\n\n                self.predictor_paths,\n                self.shapefile_path,\n                invalid_values=invalid_values\n\n            )\n\n            print(\"Clipping operation successful with the main shapefile.\")\n\n        else:\n            print(\n                \"Failed to clip the predictor data. Check the shapefile and predictor paths\")\n\n    def runAggregation(\n\n        self,\n        use_mask=False,\n        invalid_values=None,\n        calculation_mode=\"overall_mean\",\n        all_touched=False\n\n    ):\n        \"\"\"\n        Runs the aggregation process for the selected region of interest or the entire shapefile.\n\n        Args:\n            use_mask (bool): Whether to use a mask for the aggregation process.\n            invalid_values (list, optional): List of values to treat as invalid in the raster data.\n            calculation_mode (str): Determines how values are aggregated.\n            all_touched (bool): Whether to include all pixels that touch the geometry in the aggregation.\n        \"\"\"\n\n        print(\"Starting aggregation...\")\n\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n\n        aggregate_output = (\n            f'Aggregated_{calculation_mode}_{self.predictor_name}_'\n            f'{timestamp}.csv'\n        )\n\n        # Check if a Region of Interest (ROI) has been selected for aggregation\n        if self.ROI:\n\n            print(\n                f\"Starting aggregation with the selected Region of Interest (ROI) for {self.predictor_name}.\"\n            )\n\n            self.aggregated_csv = conAggregate(\n                self.predictor_dir,\n                self.ROI,\n                aggregate_output,\n                self.mask_path,\n                use_mask,\n                invalid_values,\n                calculation_mode,\n                predictor_name=self.predictor_name,\n                all_touched=all_touched\n            )\n\n        else:\n\n            print(\n                f\"Starting aggregation with the original shapefile for {self.predictor_name}.\"\n            )\n\n            self.aggregated_csv = conAggregate(\n                self.predictor_dir,\n                self.shapefile_path,\n                aggregate_output,\n                self.mask_path,\n                use_mask,\n                invalid_values,\n                calculation_mode,\n                predictor_name=self.predictor_name,\n                all_touched=all_touched\n            )\n\n        print(f\"Aggregation complete. Data saved to {aggregate_output}.\")\n\n    def runParallelAggregation(\n\n        self,\n        use_mask=False,\n        invalid_values=None,\n        calculation_mode=\"overall_mean\",\n        all_touched=False,\n        max_workers=None\n\n    ):\n        \"\"\"\n        Runs the aggregation process in parallel for the selected region of interest or the entire shapefile.\n\n        Args:\n            use_mask (bool): Whether to use a mask for the aggregation process.\n            invalid_values (list, optional): List of values to treat as invalid in the raster data.\n            calculation_mode (str): Determines how values are aggregated.\n            all_touched (bool): Whether to include all pixels that touch the geometry in the aggregation.\n        \"\"\"\n\n        print(\"Starting Parallel Aggregation...\")\n\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n\n        aggregate_output = (\n            f'Aggregated_{calculation_mode}_{self.predictor_name}_{timestamp}.csv'\n        )\n\n        # Check if a Region of Interest (ROI) has been selected for aggregation\n        if self.ROI:\n\n            print(\n                f\"Starting aggregation with the selected\"\n                f\"Region of Interest (ROI) for {self.predictor_name}.\"\n            )\n\n            self.aggregated_csv = parallelAggregate(\n                self.predictor_dir,\n                self.ROI,\n                aggregate_output,\n                self.mask_path,\n                use_mask,\n                invalid_values,\n                calculation_mode,\n                predictor_name=self.predictor_name,\n                all_touched=all_touched,\n                max_workers=max_workers\n            )\n\n        else:\n\n            print(\n                f\"Starting aggregation with the original\"\n                f\"shapefile for {self.predictor_name}.\"\n            )\n\n            self.aggregated_csv = parallelAggregate(\n                self.predictor_dir,\n                self.shapefile_path,\n                aggregate_output,\n                self.mask_path,\n                use_mask,\n                invalid_values,\n                calculation_mode,\n                predictor_name=self.predictor_name,\n                all_touched=all_touched,\n                max_workers=max_workers\n            )\n\n        print(f\"Aggregation complete. Data saved to {aggregate_output}.\")\n</code></pre>"},{"location":"earthstat/#earthstat.earthstat.EarthStat.DataCompatibility","title":"<code>DataCompatibility(self)</code>","text":"<p>Checks data compatibility among the predictor, mask, and shapefile based on spatial resolution and CRS.</p> Source code in <code>earthstat/earthstat.py</code> <pre><code>def DataCompatibility(self):\n    \"\"\"\n    Checks data compatibility among the predictor, mask, and shapefile based on spatial resolution and CRS.\n    \"\"\"\n\n    compatibility_result = checkDataCompatibility(\n\n        self.predictor_example,\n        self.mask_path,\n        self.shapefile_path\n\n    )\n\n    self.process_compatibility = compatibility_result\n\n    if self.process_compatibility['is_compatible']:\n        print(\"\\nCOMPATIBILITY CHECK PASSED: The data is compatible. \"\n              \"No resolution or projection mismatches were detected.\")\n\n    else:\n        print(\"\\nCOMPATIBILITY ISSUE DETECTED: The data is not compatible \"\n              \"based on the current checks.\")\n</code></pre>"},{"location":"earthstat/#earthstat.earthstat.EarthStat.clipPredictor","title":"<code>clipPredictor(self, invalid_values=None)</code>","text":"<p>Clips predictor data to the selected region of interest or the entire shapefile.</p> <p>Parameters:</p> Name Type Description Default <code>invalid_values</code> <code>list</code> <p>List of values to treat as invalid in the raster data.</p> <code>None</code> Source code in <code>earthstat/earthstat.py</code> <pre><code>def clipPredictor(\n\n    self,\n    invalid_values=None\n\n):\n    \"\"\"\n    Clips predictor data to the selected region of interest or the entire shapefile.\n\n    Args:\n        invalid_values (list, optional): List of values to treat as invalid in the raster data.\n    \"\"\"\n\n    print(\"Clipping the predictor data...\")\n\n    if self.ROI:\n\n        self.clipped_dir = clipRaster(\n\n            self.predictor_paths,\n            self.ROI,\n            invalid_values=invalid_values\n\n        )\n\n        print(\"Clipping operation successful with the Region of Interest (ROI).\")\n\n    elif not self.ROI:\n\n        self.clipped_dir = clipRaster(\n\n            self.predictor_paths,\n            self.shapefile_path,\n            invalid_values=invalid_values\n\n        )\n\n        print(\"Clipping operation successful with the main shapefile.\")\n\n    else:\n        print(\n            \"Failed to clip the predictor data. Check the shapefile and predictor paths\")\n</code></pre>"},{"location":"earthstat/#earthstat.earthstat.EarthStat.fixCompatibilityIssues","title":"<code>fixCompatibilityIssues(self, rescale_factor=None, resampling_method='bilinear')</code>","text":"<p>Attempts to fix any detected compatibility issues between the predictor, mask, and shapefile.</p> <p>Parameters:</p> Name Type Description Default <code>rescale_factor</code> <code>tuple</code> <p>Min and max values for rescaling the mask data.</p> <code>None</code> <code>resampling_method</code> <code>str</code> <p>Method for resampling. Defaults to 'bilinear'.</p> <code>'bilinear'</code> Source code in <code>earthstat/earthstat.py</code> <pre><code>def fixCompatibilityIssues(self, rescale_factor=None, resampling_method=\"bilinear\"):\n    \"\"\"\n    Attempts to fix any detected compatibility issues between the predictor, mask, and shapefile.\n\n    Args:\n        rescale_factor (tuple, optional): Min and max values for rescaling the mask data.\n        resampling_method (str): Method for resampling. Defaults to 'bilinear'.\n    \"\"\"\n\n    print(\"Checking for compatibility issues...\")\n\n    if not self.process_compatibility['is_compatible']:\n        print(\"Compatibility issues detected. Starting the fix process...\")\n\n        if self.process_compatibility['resample_mask']:\n            print(\n                \"- Resampling the mask to match the raster's resolution and extent.\")\n        else:\n            print(\"- The mask does not require resampling.\")\n\n        if self.process_compatibility['reproject_shapefile']:\n            print(\n                \"- Reprojecting the shapefile to match the raster's coordinate reference system.\")\n        else:\n            print(\"- The shapefile does not require reprojection.\")\n\n        updated_paths = processCompatibilityIssues(\n\n            self.process_compatibility,\n            self.mask_path,\n            self.predictor_example,\n            self.shapefile_path,\n            rescale_factor,\n            resampling_method\n\n        )\n\n        self.mask_path = updated_paths.get('crop_mask', self.mask_path)\n\n        self.shapefile_path = updated_paths.get(\n            'shapefile',\n            self.shapefile_path\n        )\n\n        if self.process_compatibility['resample_mask']:\n            print(\n                f\"Mask resampled successfully. Updated mask path: [{self.mask_path}]\")\n\n        print(\"\\nRe-checking data compatibility after applying fixes...\\n\")\n\n        self.process_compatibility = checkDataCompatibility(\n\n            self.predictor_example,\n            self.mask_path,\n            self.shapefile_path\n        )\n\n        if self.process_compatibility['is_compatible']:\n            print(\n                \"\\nAll compatibility issues have been resolved.\"\n                \"Data is now compatible.\")\n\n        else:\n            print(\n                \"Some compatibility issues could not be resolved\"\n                \"automatically. Further manual intervention required.\")\n\n    else:\n        print(\n            \"No compatibility issues detected. Predictor, mask,\"\n            \"and shapefile are already compatible.\")\n</code></pre>"},{"location":"earthstat/#earthstat.earthstat.EarthStat.initDataDir","title":"<code>initDataDir(self, data_dir)</code>","text":"<p>Initializes the directory containing predictor data, checks for data format, and optionally converts netCDF to TIFF.</p> <p>Parameters:</p> Name Type Description Default <code>data_dir</code> <code>str</code> <p>Path to the directory containing predictor data.</p> required Source code in <code>earthstat/earthstat.py</code> <pre><code>def initDataDir(self, data_dir):\n    \"\"\"\n    Initializes the directory containing predictor data, checks for data format, and optionally converts netCDF to TIFF.\n\n    Args:\n        data_dir (str): Path to the directory containing predictor data.\n    \"\"\"\n    has_tiff = any(file.endswith('.tif') for file in os.listdir(data_dir))\n\n    if has_tiff:\n        print(\"TIFF data found. Loading...\\n\")\n        # Proceed to load TIFF data without conversion\n        self.predictor_paths = loadTiff(data_dir)\n\n    else:\n        # If no TIFF files, check for netCDF files\n        has_netcdf = any(file.endswith('.nc')\n                         for file in os.listdir(data_dir))\n\n        if has_netcdf:\n            convert_choice = input(\n                \"The data is in netCDF format. Do you want to convert it to TIFF? (y/n): \")\n\n            if convert_choice.lower() == 'y':\n\n                # If user chooses to convert, convert the data to TIFF\n                data_dir = convertToTIFF(data_dir)\n                print(\"Data converted to TIFF successfully.\\n\")\n                self.predictor_paths = loadTiff(data_dir)\n\n            else:\n\n                print(\n                    \"Data will not be converted. EarthStat just works with TIFF data.\")\n                return\n\n        else:\n            print(\"No netCDF or TIFF data found in the directory.\")\n            return\n\n    self.predictor_dir = data_dir\n    self.predictor_example = self.predictor_paths[0]\n    self.predictory_meta = predictorMeta(data_dir, self.predictor_name)\n    print(\"\\nPredictor Paths Initialized Correctly, Initialize The Mask's Path\")\n</code></pre>"},{"location":"earthstat/#earthstat.earthstat.EarthStat.initMaskPath","title":"<code>initMaskPath(self, mask_path)</code>","text":"<p>Initializes the path to the mask raster and extracts its metadata.</p> <p>Parameters:</p> Name Type Description Default <code>mask_path</code> <code>str</code> <p>Path to the mask raster file.</p> required Source code in <code>earthstat/earthstat.py</code> <pre><code>def initMaskPath(self, mask_path):\n    \"\"\"\n    Initializes the path to the mask raster and extracts its metadata.\n\n    Args:\n        mask_path (str): Path to the mask raster file.\n    \"\"\"\n\n    self.mask_path = mask_path\n    # Function to identify mask information\n    self.mask_meta = maskSummary(self.mask_path)\n    print(\"\\nMask Initialized Correctly, Initialize The Shapefile\")\n</code></pre>"},{"location":"earthstat/#earthstat.earthstat.EarthStat.initShapefilePath","title":"<code>initShapefilePath(self, shapefile_path)</code>","text":"<p>Initializes the path to the shapefile and extracts its metadata.</p> <p>Parameters:</p> Name Type Description Default <code>shapefile_path</code> <code>str</code> <p>Path to the shapefile.</p> required Source code in <code>earthstat/earthstat.py</code> <pre><code>def initShapefilePath(self, shapefile_path):\n    \"\"\"\n    Initializes the path to the shapefile and extracts its metadata.\n\n    Args:\n        shapefile_path (str): Path to the shapefile.\n    \"\"\"\n\n    self.shapefile_path = shapefile_path\n    self.shapefile_meta = shapefileMeta(self.shapefile_path)\n\n    if self.mask_path and self.predictor_paths:\n        print(\n            \"\\nShapefile Initialized Correctly, You Can Check The Data Compatibility\")\n    else:\n        print(\n            \"\\nShapefile Initialized Correctly, But The Mask or Predictor Paths are not initialized\")\n</code></pre>"},{"location":"earthstat/#earthstat.earthstat.EarthStat.runAggregation","title":"<code>runAggregation(self, use_mask=False, invalid_values=None, calculation_mode='overall_mean', all_touched=False)</code>","text":"<p>Runs the aggregation process for the selected region of interest or the entire shapefile.</p> <p>Parameters:</p> Name Type Description Default <code>use_mask</code> <code>bool</code> <p>Whether to use a mask for the aggregation process.</p> <code>False</code> <code>invalid_values</code> <code>list</code> <p>List of values to treat as invalid in the raster data.</p> <code>None</code> <code>calculation_mode</code> <code>str</code> <p>Determines how values are aggregated.</p> <code>'overall_mean'</code> <code>all_touched</code> <code>bool</code> <p>Whether to include all pixels that touch the geometry in the aggregation.</p> <code>False</code> Source code in <code>earthstat/earthstat.py</code> <pre><code>def runAggregation(\n\n    self,\n    use_mask=False,\n    invalid_values=None,\n    calculation_mode=\"overall_mean\",\n    all_touched=False\n\n):\n    \"\"\"\n    Runs the aggregation process for the selected region of interest or the entire shapefile.\n\n    Args:\n        use_mask (bool): Whether to use a mask for the aggregation process.\n        invalid_values (list, optional): List of values to treat as invalid in the raster data.\n        calculation_mode (str): Determines how values are aggregated.\n        all_touched (bool): Whether to include all pixels that touch the geometry in the aggregation.\n    \"\"\"\n\n    print(\"Starting aggregation...\")\n\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n\n    aggregate_output = (\n        f'Aggregated_{calculation_mode}_{self.predictor_name}_'\n        f'{timestamp}.csv'\n    )\n\n    # Check if a Region of Interest (ROI) has been selected for aggregation\n    if self.ROI:\n\n        print(\n            f\"Starting aggregation with the selected Region of Interest (ROI) for {self.predictor_name}.\"\n        )\n\n        self.aggregated_csv = conAggregate(\n            self.predictor_dir,\n            self.ROI,\n            aggregate_output,\n            self.mask_path,\n            use_mask,\n            invalid_values,\n            calculation_mode,\n            predictor_name=self.predictor_name,\n            all_touched=all_touched\n        )\n\n    else:\n\n        print(\n            f\"Starting aggregation with the original shapefile for {self.predictor_name}.\"\n        )\n\n        self.aggregated_csv = conAggregate(\n            self.predictor_dir,\n            self.shapefile_path,\n            aggregate_output,\n            self.mask_path,\n            use_mask,\n            invalid_values,\n            calculation_mode,\n            predictor_name=self.predictor_name,\n            all_touched=all_touched\n        )\n\n    print(f\"Aggregation complete. Data saved to {aggregate_output}.\")\n</code></pre>"},{"location":"earthstat/#earthstat.earthstat.EarthStat.runParallelAggregation","title":"<code>runParallelAggregation(self, use_mask=False, invalid_values=None, calculation_mode='overall_mean', all_touched=False, max_workers=None)</code>","text":"<p>Runs the aggregation process in parallel for the selected region of interest or the entire shapefile.</p> <p>Parameters:</p> Name Type Description Default <code>use_mask</code> <code>bool</code> <p>Whether to use a mask for the aggregation process.</p> <code>False</code> <code>invalid_values</code> <code>list</code> <p>List of values to treat as invalid in the raster data.</p> <code>None</code> <code>calculation_mode</code> <code>str</code> <p>Determines how values are aggregated.</p> <code>'overall_mean'</code> <code>all_touched</code> <code>bool</code> <p>Whether to include all pixels that touch the geometry in the aggregation.</p> <code>False</code> Source code in <code>earthstat/earthstat.py</code> <pre><code>def runParallelAggregation(\n\n    self,\n    use_mask=False,\n    invalid_values=None,\n    calculation_mode=\"overall_mean\",\n    all_touched=False,\n    max_workers=None\n\n):\n    \"\"\"\n    Runs the aggregation process in parallel for the selected region of interest or the entire shapefile.\n\n    Args:\n        use_mask (bool): Whether to use a mask for the aggregation process.\n        invalid_values (list, optional): List of values to treat as invalid in the raster data.\n        calculation_mode (str): Determines how values are aggregated.\n        all_touched (bool): Whether to include all pixels that touch the geometry in the aggregation.\n    \"\"\"\n\n    print(\"Starting Parallel Aggregation...\")\n\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n\n    aggregate_output = (\n        f'Aggregated_{calculation_mode}_{self.predictor_name}_{timestamp}.csv'\n    )\n\n    # Check if a Region of Interest (ROI) has been selected for aggregation\n    if self.ROI:\n\n        print(\n            f\"Starting aggregation with the selected\"\n            f\"Region of Interest (ROI) for {self.predictor_name}.\"\n        )\n\n        self.aggregated_csv = parallelAggregate(\n            self.predictor_dir,\n            self.ROI,\n            aggregate_output,\n            self.mask_path,\n            use_mask,\n            invalid_values,\n            calculation_mode,\n            predictor_name=self.predictor_name,\n            all_touched=all_touched,\n            max_workers=max_workers\n        )\n\n    else:\n\n        print(\n            f\"Starting aggregation with the original\"\n            f\"shapefile for {self.predictor_name}.\"\n        )\n\n        self.aggregated_csv = parallelAggregate(\n            self.predictor_dir,\n            self.shapefile_path,\n            aggregate_output,\n            self.mask_path,\n            use_mask,\n            invalid_values,\n            calculation_mode,\n            predictor_name=self.predictor_name,\n            all_touched=all_touched,\n            max_workers=max_workers\n        )\n\n    print(f\"Aggregation complete. Data saved to {aggregate_output}.\")\n</code></pre>"},{"location":"earthstat/#earthstat.earthstat.EarthStat.selectRegionOfInterest","title":"<code>selectRegionOfInterest(self, countries, country_column_name)</code>","text":"<p>Selects a region of interest (ROI) within the shapefile based on specified countries.</p> <p>Parameters:</p> Name Type Description Default <code>countries</code> <code>list of str</code> <p>Countries to include in the ROI.</p> required <code>country_column_name</code> <code>str</code> <p>Column name in the shapefile containing country names.</p> required Source code in <code>earthstat/earthstat.py</code> <pre><code>def selectRegionOfInterest(self, countries, country_column_name):\n    \"\"\"\n    Selects a region of interest (ROI) within the shapefile based on specified countries.\n\n    Args:\n        countries (list of str): Countries to include in the ROI.\n        country_column_name (str): Column name in the shapefile containing country names.\n    \"\"\"\n\n    self.ROI = extractROI(\n\n        self.shapefile_path,\n        countries,\n        country_column_name\n\n    )\n\n    if self.ROI:\n\n        print(\n            f\"Region of Interest (ROI) successfully selected based on \"\n            f\"the specified countries: {', '.join(countries)}.\")\n\n    else:\n        print(\"Failed to select the Region of Interest (ROI).\"\n              \"Please check the country names and column name provided.\")\n</code></pre>"},{"location":"faq/","title":"FAQ","text":""},{"location":"geo_data_processing/","title":"EarthStat Geo Data Processing Documentation","text":"<p>Comprehensive guide to the <code>earthstat.geo_data_processing</code> module functionalities, designed for geospatial data manipulation and analysis.</p>"},{"location":"geo_data_processing/#raster-data-manipulation","title":"Raster Data Manipulation","text":""},{"location":"geo_data_processing/#clipping-raster-data-for-area-of-interest","title":"Clipping Raster Data for Area of Interest","text":""},{"location":"geo_data_processing/#earthstat.geo_data_processing.clip_raster.clipMultipleRasters","title":"<code>clipMultipleRasters(raster_paths, shapefile_path, invalid_values=None)</code>","text":"<p>Clips a raster file using a shapefile, optionally filtering out specified invalid values. The clipped raster is saved in a new directory named 'clipped' plus the original file directory.</p> <p>Parameters:</p> Name Type Description Default <code>raster_path</code> <code>str</code> <p>Path to the raster file to be clipped.</p> required <code>shapefile_path</code> <code>str</code> <p>Path to the shapefile used for clipping.</p> required <code>invalid_values</code> <code>list</code> <p>Values in the raster to treat as invalid and replace with NaN.</p> <code>None</code> <p>The function creates a new directory (if it doesn't already exist) and saves the clipped raster there.</p> Source code in <code>earthstat/geo_data_processing/clip_raster.py</code> <pre><code>def clipMultipleRasters(raster_paths, shapefile_path, invalid_values=None):\n    \"\"\"\n    Clips a raster file using a shapefile, optionally filtering out specified invalid values.\n    The clipped raster is saved in a new directory named 'clipped' plus the original file directory.\n\n    Args:\n        raster_path (str): Path to the raster file to be clipped.\n        shapefile_path (str): Path to the shapefile used for clipping.\n        invalid_values (list, optional): Values in the raster to treat as invalid and replace with NaN.\n\n    The function creates a new directory (if it doesn't already exist) and saves the clipped raster there.\n    \"\"\"\n\n    # Enhancement: by open shapefile and create dir our of the loop\n    output_clip_dir = os.path.join(os.path.dirname(raster_paths[0]), 'clipped')\n    os.makedirs(output_clip_dir, exist_ok=True)\n\n    shapefile = gpd.read_file(shapefile_path)\n\n    # Using ProcessPoolExecutor to parallelize the task\n    with ProcessPoolExecutor(max_workers=os.cpu_count()) as executor:\n\n        # Use list to force execution and tqdm for progress bar\n        list(tqdm(executor.map(clipRasterWithShapefile, raster_paths, [shapefile]*len(raster_paths), [invalid_values]*len(raster_paths)),\n                  total=len(raster_paths), desc=\"Clipping Rasters\"))\n\n    return output_clip_dir\n</code></pre>"},{"location":"geo_data_processing/#earthstat.geo_data_processing.clip_raster.clipRasterWithShapefile","title":"<code>clipRasterWithShapefile(raster_path, shapefile, invalid_values=None)</code>","text":"<p>Clips multiple raster files using a single shapefile, optionally filtering out specified invalid values. Each clipped raster is saved in a new directory named 'clipped' plus the original file directory.</p> <p>Parameters:</p> Name Type Description Default <code>raster_paths</code> <code>list of str</code> <p>Paths to the raster files to be clipped.</p> required <code>shapefile_path</code> <code>str</code> <p>Path to the shapefile used for clipping.</p> required <code>invalid_values</code> <code>list</code> <p>Values in the raster to treat as invalid and replace with NaN.</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>The path to the directory where clipped rasters are saved.</p> <p>Processes each raster sequentially, showing progress with a progress bar.</p> Source code in <code>earthstat/geo_data_processing/clip_raster.py</code> <pre><code>def clipRasterWithShapefile(raster_path, shapefile, invalid_values=None):\n    \"\"\"\n    Clips multiple raster files using a single shapefile, optionally filtering out specified invalid values.\n    Each clipped raster is saved in a new directory named 'clipped' plus the original file directory.\n\n    Args:\n        raster_paths (list of str): Paths to the raster files to be clipped.\n        shapefile_path (str): Path to the shapefile used for clipping.\n        invalid_values (list, optional): Values in the raster to treat as invalid and replace with NaN.\n\n    Returns:\n        str: The path to the directory where clipped rasters are saved.\n\n    Processes each raster sequentially, showing progress with a progress bar.\n    \"\"\"\n    file_dir, file_name = os.path.split(raster_path)\n\n    output_clip = os.path.join(file_dir, 'clipped')\n\n    with rasterio.open(raster_path) as src:\n        geoms = [mapping(shape) for shape in shapefile.geometry]\n        out_image, out_transform = mask(src, geoms, crop=True)\n        if invalid_values:\n            for invalid_value in invalid_values:\n                out_image = np.where(\n                    out_image == invalid_value, np.nan, out_image)\n\n        out_meta = src.meta.copy()\n        out_meta.update({\n            \"driver\": \"GTiff\",\n            \"height\": out_image.shape[1],\n            \"width\": out_image.shape[2],\n            \"transform\": out_transform,\n            \"dtype\": 'float32',\n            \"compress\": \"lzw\"\n        })\n\n    output_path = os.path.join(output_clip, f\"clipped_{file_name}\")\n    with rasterio.open(output_path, \"w\", **out_meta) as dest:\n        dest.write(out_image)\n</code></pre>"},{"location":"geo_data_processing/#rescaling-and-resampling-for-data-uniformity","title":"Rescaling and Resampling for Data Uniformity","text":""},{"location":"geo_data_processing/#earthstat.geo_data_processing.rescale_resample_raster.rescaleResampleMask","title":"<code>rescaleResampleMask(mask_path, raster_data_path, scale_factor=None, resampling_method='bilinear')</code>","text":"<p>Rescales and resamples a mask raster based on a target raster's specifications.  Optionally applies scaling to the mask data's values and resamples using a specified method.</p> <p>Parameters:</p> Name Type Description Default <code>mask_path</code> <code>str</code> <p>Path to the mask raster file to be rescaled and resampled.</p> required <code>raster_data_path</code> <code>str</code> <p>Path to the target raster file for matching specifications.</p> required <code>scale_factor</code> <code>tuple</code> <p>Min and max values for rescaling the mask data. Defaults to None.</p> <code>None</code> <code>resampling_method</code> <code>str</code> <p>Method for resampling ('bilinear', 'cubic', 'average', 'nearest'.). Defaults to bilinear.</p> <code>'bilinear'</code> <p>Returns:</p> Type Description <code>str</code> <p>The path to the saved rescaled and resampled raster file.</p> Source code in <code>earthstat/geo_data_processing/rescale_resample_raster.py</code> <pre><code>def rescaleResampleMask(mask_path, raster_data_path, scale_factor=None, resampling_method=\"bilinear\"):\n    \"\"\"\n    Rescales and resamples a mask raster based on a target raster's specifications. \n    Optionally applies scaling to the mask data's values and resamples using a specified method.\n\n    Args:\n        mask_path (str): Path to the mask raster file to be rescaled and resampled.\n        raster_data_path (str): Path to the target raster file for matching specifications.\n        scale_factor (tuple, optional): Min and max values for rescaling the mask data. Defaults to None.\n        resampling_method (str, optional): Method for resampling ('bilinear', 'cubic', 'average', 'nearest'.). Defaults to bilinear.\n\n    Returns:\n        str: The path to the saved rescaled and resampled raster file.\n    \"\"\"\n    file_dir, file_name = savedFilePath(mask_path)\n\n    resampling_enum = resamplingMethod(resampling_method)\n\n    with rasterio.open(raster_data_path) as target_raster:\n        target_transform = target_raster.transform\n\n    with rasterio.open(mask_path) as mask:\n        mask_data = mask.read(1)\n\n        if scale_factor:\n            # Use actual min and max from the data\n            old_min, old_max = mask_data.min(), mask_data.max()\n            new_min, new_max = scale_factor\n            rescaled_data = ((mask_data - old_min) /\n                             (old_max - old_min)) * (new_max - new_min) + new_min\n            print(\"\\nRescaling Mask...\")\n            print(\"Resampling mask...\")\n        else:\n            rescaled_data = mask_data  # Skip rescaling if scale_factor is None\n            print(\"\\nResampling mask...\")\n        out_meta = mask.meta.copy()\n        out_meta.update({\n            \"driver\": \"GTiff\",\n            \"height\": target_raster.height,\n            \"width\": target_raster.width,\n            \"transform\": target_transform,\n            \"crs\": target_raster.crs,\n            \"compress\": \"DEFLATE\",  # Future Enhancement:specify best compression scheme here\n            \"predictor\": \"2\",  # !!! good for continuous data !!!\n            \"zlevel\": 1  # compression level, 9 is the highest\n        })\n\n    resampled_data = np.empty(\n        shape=(target_raster.height, target_raster.width), dtype=out_meta['dtype'])\n    warp.reproject(\n        source=rescaled_data,\n        destination=resampled_data,\n        src_transform=mask.transform,\n        src_crs=mask.crs,\n        dst_transform=target_transform,\n        dst_crs=target_raster.crs,\n        resampling=resampling_enum\n    )\n\n    output_path = f'{file_dir}/rescaled_resampled_{resampling_method}_{file_name}'\n\n    with rasterio.open(output_path, \"w\", **out_meta) as dest:\n        dest.write(resampled_data, 1)\n\n    print(f\"Filtered shapefile saved to: {output_path}\")\n\n    return output_path\n</code></pre>"},{"location":"geo_data_processing/#shapefile-handling","title":"Shapefile Handling","text":""},{"location":"geo_data_processing/#efficient-shapefile-processing-techniques","title":"Efficient Shapefile Processing Techniques","text":""},{"location":"geo_data_processing/#earthstat.geo_data_processing.shapefile_process.filterShapefile","title":"<code>filterShapefile(shapefile_path, countries, country_column_name)</code>","text":"<p>Filters a shapefile based on a list of country names within a specified column.</p> <p>Parameters:</p> Name Type Description Default <code>shapefile_path</code> <code>str</code> <p>Path to the shapefile to be filtered.</p> required <code>countries</code> <code>list of str</code> <p>List of country names to filter by.</p> required <code>country_column_name</code> <code>str</code> <p>Column name in the shapefile that contains country names.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Path to the filtered shapefile saved in the same directory as the original.</p> Source code in <code>earthstat/geo_data_processing/shapefile_process.py</code> <pre><code>def filterShapefile(shapefile_path, countries, country_column_name):\n    \"\"\"\n    Filters a shapefile based on a list of country names within a specified column.\n\n    Args:\n        shapefile_path (str): Path to the shapefile to be filtered.\n        countries (list of str): List of country names to filter by.\n        country_column_name (str): Column name in the shapefile that contains country names.\n\n    Returns:\n        str: Path to the filtered shapefile saved in the same directory as the original.\n    \"\"\"\n    file_dir, file_name = savedFilePath(shapefile_path)\n    gdf = gpd.read_file(shapefile_path)\n    filtered_gdf = gdf[gdf[country_column_name].isin(countries)]\n    output_path = f'{file_dir}/filtered_{file_name}'\n    filtered_gdf.to_file(output_path)\n    print(f\"Filtered shapefile saved to: {output_path}\")\n    return output_path\n</code></pre>"},{"location":"geo_data_processing/#earthstat.geo_data_processing.shapefile_process.reprojectShapefileToRaster","title":"<code>reprojectShapefileToRaster(raster_data_path, shapefile_path)</code>","text":"<p>Reprojects a shapefile to match the Coordinate Reference System (CRS) of a given raster file.</p> <p>Parameters:</p> Name Type Description Default <code>raster_data_path</code> <code>str</code> <p>Path to the raster file whose CRS is to be matched.</p> required <code>shapefile_path</code> <code>str</code> <p>Path to the shapefile to be reprojected.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Path to the reprojected shapefile saved in the same directory as the original.</p> Source code in <code>earthstat/geo_data_processing/shapefile_process.py</code> <pre><code>def reprojectShapefileToRaster(raster_data_path, shapefile_path):\n    \"\"\"\n    Reprojects a shapefile to match the Coordinate Reference System (CRS) of a given raster file.\n\n    Args:\n        raster_data_path (str): Path to the raster file whose CRS is to be matched.\n        shapefile_path (str): Path to the shapefile to be reprojected.\n\n    Returns:\n        str: Path to the reprojected shapefile saved in the same directory as the original.\n    \"\"\"\n    file_dir, file_name = savedFilePath(shapefile_path)\n    with rasterio.open(raster_data_path) as src:\n        raster_crs = src.crs\n\n    shapefile = gpd.read_file(shapefile_path)\n    output_path = f'{file_dir}/reprojected_{file_name}'\n    shapefile_reprojected = shapefile.to_crs(raster_crs)\n    shapefile_reprojected.to_file(output_path)\n\n    print(\n        f\"Shapefile reprojected to match raster CRS and saved to {output_path}\")\n    return output_path\n</code></pre>"},{"location":"geo_meta_extractor/","title":"Geospatial Metadata Extraction Toolkit Documentation","text":"<p>Detailed overview of the <code>earthstat.geo_meta_extractors</code> module, offering specialized tools for extracting metadata from various geospatial data formats.</p>"},{"location":"geo_meta_extractor/#metadata-extraction-capabilities","title":"Metadata Extraction Capabilities","text":""},{"location":"geo_meta_extractor/#extracting-predictor-variables-from-metadata","title":"Extracting Predictor Variables from Metadata","text":""},{"location":"geo_meta_extractor/#earthstat.geo_meta_extractors.predictor_meta.predictorMeta","title":"<code>predictorMeta(predictor_dir, predictor_name)</code>","text":"<p>Generates a summary of TIFF files within a specified directory, providing essential metadata about the geospatial data contained in these files. This function specifically looks for <code>.tif</code> files, extracting dates, spatial resolution, Coordinate Reference System (CRS), and other relevant metadata.</p> <p>The summary also includes: total number of TIFF files, the directory path, CRS, spatial extent, data type, NoData value, spatial resolution in pixels, and pixel size.</p> <p>Parameters:</p> Name Type Description Default <code>predictor_dir</code> <code>str</code> <p>The path to the directory containing TIFF files. This directory is expected to exist and contain at least one <code>.tif</code> file.</p> required <code>predictor_name</code> <code>str</code> <p>A descriptive name for the predictor. This name is used purely for identification purposes in the summary output.</p> required <p>Exceptions:</p> Type Description <code>FileNotFoundError</code> <p>If <code>predictor_dir</code> does not exist or contains no <code>.tif</code> files.</p> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary containing extracted metadata.</p> Source code in <code>earthstat/geo_meta_extractors/predictor_meta.py</code> <pre><code>def predictorMeta(predictor_dir, predictor_name):\n    \"\"\"\n    Generates a summary of TIFF files within a specified directory, providing\n    essential metadata about the geospatial data contained in these files.\n    This function specifically looks for `.tif` files, extracting dates, spatial\n    resolution, Coordinate Reference System (CRS), and other relevant metadata.\n\n    The summary also includes: total number of TIFF files, the directory path, CRS, spatial extent, data type,\n    NoData value, spatial resolution in pixels, and pixel size.\n\n    Args:\n        predictor_dir (str): The path to the directory containing TIFF files.\n            This directory is expected to exist and contain at least one `.tif` file.\n        predictor_name (str): A descriptive name for the predictor. This name is\n            used purely for identification purposes in the summary output.\n\n    Raises:\n        FileNotFoundError: If `predictor_dir` does not exist or contains no `.tif` files.\n\n    Returns:\n        dict: A dictionary containing extracted metadata.\n    \"\"\"\n    if not os.path.exists(predictor_dir):\n\n        raise FileNotFoundError(\n            f\"The directory {predictor_dir} does not exist.\")\n\n    paths = glob.glob(os.path.join(predictor_dir, '*.tif'))\n    if not paths:\n        return \"No TIFF files found. Please ensure the directory is correct and contains TIFF files.\"\n\n    dates = [convDate(exDate(os.path.basename(path))) for path in paths]\n    date_range = f\"{min(dates)} to {max(dates)}\" if dates else \"No identifiable dates.\"\n\n    with rasterio.open(paths[0]) as src:\n        width, height = src.width, src.height\n        crs = CRS(src.crs).name\n\n    predictor_summary = {\n        \"predictor\": predictor_name,\n        \"total_tiff_files\": len(paths),\n        \"date_range\": date_range,\n        \"directory\": predictor_dir,\n        \"CRS\": crs,\n        \"Extent\": src.bounds,\n        \"Data Type\": src.dtypes[0],\n        \"NoData Value\": src.nodatavals[0],\n        \"Spatial Resolution\": f\"{width}x{height}\",\n        \"Pixel Size\": src.res\n    }\n    print(\"Predictor Summary:\\n\")\n    print('\\n'.join(f\"{key}: {value}\" for key,\n          value in predictor_summary.items()))\n    return predictor_summary\n</code></pre>"},{"location":"geo_meta_extractor/#generating-metadata-masks-for-geospatial-analysis","title":"Generating Metadata Masks for Geospatial Analysis","text":""},{"location":"geo_meta_extractor/#earthstat.geo_meta_extractors.mask_meta.maskSummary","title":"<code>maskSummary(raster_path)</code>","text":"<p>Generates a summary of a single-band raster file, including CRS, extent, data type,  NoData value, resolution, pixel size, and min/max values. Assumes the file is readable  by rasterio and contains geospatial data.</p> <p>Parameters:</p> Name Type Description Default <code>raster_path</code> <code>str</code> <p>Path to the raster file.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Summary of raster properties. Includes 'Mask_path', 'CRS', 'Extent',        'Data Type', 'NoData Value', 'Spatial Resolution', 'Pixel Size',        and 'Min/Max Value'.</p> Source code in <code>earthstat/geo_meta_extractors/mask_meta.py</code> <pre><code>def maskSummary(raster_path):\n    \"\"\"\n    Generates a summary of a single-band raster file, including CRS, extent, data type, \n    NoData value, resolution, pixel size, and min/max values. Assumes the file is readable \n    by rasterio and contains geospatial data.\n\n    Args:\n        raster_path (str): Path to the raster file.\n\n    Returns:\n        dict: Summary of raster properties. Includes 'Mask_path', 'CRS', 'Extent', \n              'Data Type', 'NoData Value', 'Spatial Resolution', 'Pixel Size', \n              and 'Min/Max Value'.\n    \"\"\"\n    with rasterio.open(raster_path) as src:\n\n        # Assuming there is a single band\n        band_data = src.read(1, masked=True)\n\n        # Compute minimum and maximum values\n        min_value = band_data.min()\n        max_value = band_data.max()\n        crs = CRS(src.crs).name\n\n        # Extracting essential information\n        mask_summary = {\n            \"Mask_path\": raster_path,\n            \"CRS\": crs,\n            \"Extent\": src.bounds,\n            \"Data Type\": src.dtypes[0],\n            \"NoData Value\": src.nodatavals[0],\n            \"Spatial Resolution\": (src.width, src.height),\n            \"Pixel Size\": src.res,\n            \"Min/Max Value\": (min_value, max_value)\n        }\n\n        print(\"Mask Summary:\\n\")\n        print('\\n'.join(f\"{key}: {value}\" for key,\n              value in mask_summary.items()))\n\n        return mask_summary\n</code></pre>"},{"location":"geo_meta_extractor/#shapefile-metadata-extraction-for-enhanced-data-insight","title":"Shapefile Metadata Extraction for Enhanced Data Insight","text":""},{"location":"geo_meta_extractor/#earthstat.geo_meta_extractors.shapefile_meta.shapefileMeta","title":"<code>shapefileMeta(shapefile_path)</code>","text":"<p>Summarizes key metadata of a shapefile, including geometry types, CRS, extent, feature count, and attribute names. Assumes the shapefile can be read using GeoPandas.</p> <p>Parameters:</p> Name Type Description Default <code>shapefile_path</code> <code>str</code> <p>Path to the shapefile.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Contains 'Geometry Type', 'Coordinate Reference System (CRS)', 'Extent',       'Feature Count', and 'Attributes' of the shapefile.</p> Source code in <code>earthstat/geo_meta_extractors/shapefile_meta.py</code> <pre><code>def shapefileMeta(shapefile_path):\n    \"\"\"\n    Summarizes key metadata of a shapefile, including geometry types, CRS, extent,\n    feature count, and attribute names. Assumes the shapefile can be read using\n    GeoPandas.\n\n    Args:\n        shapefile_path (str): Path to the shapefile.\n\n    Returns:\n        dict: Contains 'Geometry Type', 'Coordinate Reference System (CRS)', 'Extent',\n              'Feature Count', and 'Attributes' of the shapefile.\n    \"\"\"\n    # Load the shapefile\n    gdf = gpd.read_file(shapefile_path)\n    crs = CRS(gdf.crs).name\n\n    # Extracting essential information\n    shapefile_meta = {\n        \"Geometry Type\": gdf.geometry.type.unique(),\n        \"Coordinate Reference System (CRS)\": crs,\n        \"Extent\": gdf.total_bounds,\n        \"Feature Count\": len(gdf),\n        \"Attributes\": list(gdf.columns)\n    }\n    print(\"Shapefile Summary:\\n\")\n    print('\\n'.join(f\"{key}: {value}\" for key,\n                    value in shapefile_meta.items()))\n\n    return shapefile_meta\n</code></pre>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#stable-release","title":"Stable release","text":"<p>To install EarthStat, run this command in your terminal:</p> <pre><code>pip install earthstat\n</code></pre> <p>This is the preferred method to install EarthStat, as it will always install the most recent stable release.</p> <p>If you don't have pip installed, this Python installation guide can guide you through the process.</p>"},{"location":"installation/#from-sources","title":"From sources","text":"<p>To install EarthStat from sources, run this command in your terminal:</p> <pre><code>pip install git+https://github.com/AbdelrahmanAmr3/earthstat\n</code></pre>"},{"location":"utils/","title":"Earth's Utilities","text":"<p>Detailed documentation on the <code>earthstat.utils</code> module, a collection of functions designed usually used through building the EarthStat library. </p>"},{"location":"utils/#utilities-overview","title":"Utilities Overview","text":""},{"location":"utils/#earthstat.utils.convertDate","title":"<code>convertDate(date)</code>","text":"<p>Converts a date string from 'YYYYMMDD' format to a date object.</p> <p>Parameters:</p> Name Type Description Default <code>date</code> <code>str</code> <p>The date string in 'YYYYMMDD' format.</p> required <p>Returns:</p> Type Description <code>datetime.date</code> <p>The corresponding date object.</p> Source code in <code>earthstat/utils.py</code> <pre><code>def convertDate(date):\n    \"\"\"\n    Converts a date string from 'YYYYMMDD' format to a date object.\n\n    Args:\n        date (str): The date string in 'YYYYMMDD' format.\n\n    Returns:\n        datetime.date: The corresponding date object.\n    \"\"\"\n    return datetime.strptime(date, '%Y%m%d').date()\n</code></pre>"},{"location":"utils/#earthstat.utils.extractDateFromFilename","title":"<code>extractDateFromFilename(filename)</code>","text":"<p>Extracts a date string in 'YYYYMMDD' format from a filename.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The name of the file containing a date.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The extracted date string.</p> Source code in <code>earthstat/utils.py</code> <pre><code>def extractDateFromFilename(filename):\n    \"\"\"\n    Extracts a date string in 'YYYYMMDD' format from a filename.\n\n    Args:\n        filename (str): The name of the file containing a date.\n\n    Returns:\n        str: The extracted date string.\n    \"\"\"\n    pattern = r'\\d{8}'\n    match = re.search(pattern, filename)\n    date_str = match.group()\n    return date_str\n</code></pre>"},{"location":"utils/#earthstat.utils.loadTiff","title":"<code>loadTiff(directory)</code>","text":"<p>Loads and returns paths to all TIFF files in a specified directory.</p> <p>Parameters:</p> Name Type Description Default <code>directory</code> <code>str</code> <p>The directory to search for TIFF files.</p> required <p>Returns:</p> Type Description <code>list</code> <p>A list of paths to the TIFF files found in the directory.</p> Source code in <code>earthstat/utils.py</code> <pre><code>def loadTiff(directory):\n    \"\"\"\n    Loads and returns paths to all TIFF files in a specified directory.\n\n    Args:\n        directory (str): The directory to search for TIFF files.\n\n    Returns:\n        list: A list of paths to the TIFF files found in the directory.\n    \"\"\"\n    paths = glob.glob(directory+'/*.tif')\n    return paths\n</code></pre>"},{"location":"utils/#earthstat.utils.savedFilePath","title":"<code>savedFilePath(file_path)</code>","text":"<p>Extracts and returns the directory and name of a file from its path.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>The full path to the file.</p> required <p>Returns:</p> Type Description <code>tuple</code> <p>A tuple containing the file's directory and name.</p> Source code in <code>earthstat/utils.py</code> <pre><code>def savedFilePath(file_path):\n    \"\"\"\n    Extracts and returns the directory and name of a file from its path.\n\n    Args:\n        file_path (str): The full path to the file.\n\n    Returns:\n        tuple: A tuple containing the file's directory and name.\n    \"\"\"\n    file_dir = os.path.dirname(file_path)\n    file_name = os.path.basename(file_path)\n\n    return file_dir, file_name\n</code></pre>"},{"location":"examples/intro/","title":"Intro","text":"In\u00a0[1]: Copied! <pre>!pip install earthstat\n</pre> !pip install earthstat In\u00a0[2]: Copied! <pre>from earthstat import EarthStat\n</pre> from earthstat import EarthStat <p>Initialize the core settings:</p> <ul> <li><code>predictor_name</code>: The name of the predictor being used.</li> <li><code>predictor_dir</code>: The directory where the predictor's related files are stored.</li> <li><code>mask_file_path</code>: The file path to the mask file, used for calculate weighted mean or mask the raster.</li> <li><code>shapefile_file_path</code>: Path to the shapefile containing geographical boundaries.</li> <li><code>selected_countries</code>: A list of countries - Region of interest (ROI).</li> <li><code>country_column_name</code>: The column's name in the dataset that contains country names.</li> <li><code>invalid_values</code>: A list of values considered invalid within the dataset.</li> </ul> <p>Important: Be sure to set <code>invalid_values</code> to <code>None</code> if you do not wish to exclude any values from the dataset's rasters.</p> In\u00a0[3]: Copied! <pre>predictor_name              = 'FPAR'\npredictor_dir               = 'FPAR'\nmask_file_path              = 'crop mask/asap_mask_crop_v04.tif'\nshapefile_file_path         = 'shapefile/gaul1_asap.shp'\nselected_countries          = [\"Norway\", \"Spain\"]\t\ncountry_column_name         = 'adm0_name'\ninvalid_values              = [255, 254, 251]\n</pre> predictor_name              = 'FPAR' predictor_dir               = 'FPAR' mask_file_path              = 'crop mask/asap_mask_crop_v04.tif' shapefile_file_path         = 'shapefile/gaul1_asap.shp' selected_countries          = [\"Norway\", \"Spain\"]\t country_column_name         = 'adm0_name' invalid_values              = [255, 254, 251]  <p>Important To know that:</p> <p>Caution: An increase in ROI size may lead to system crashes for normal processing due to insuffienct RAM size.</p> In\u00a0[\u00a0]: Copied! <pre>fpar_aggregator = EarthStat(predictor_name)\n</pre> fpar_aggregator = EarthStat(predictor_name) In\u00a0[4]: Copied! <pre>fpar_aggregator.initDataDir(predictor_dir)\n</pre> fpar_aggregator.initDataDir(predictor_dir) <pre>TIFF data found. Loading...\n\nPredictor Summary:\n\npredictor: FPAR\ntotal_tiff_files: 2\ndate_range: 2015-07-21 to 2015-08-01\ndirectory: FPAR\nCRS: WGS 84\nExtent: BoundingBox(left=-180.004464285715, bottom=-56.00446430667502, right=179.99553577188502, top=75.004464285715)\nData Type: uint8\nNoData Value: 255.0\nSpatial Resolution: 80640x29346\nPixel Size: (0.004464285715, 0.004464285715)\n\nPredictor Paths Initialized Correctly, Initialize The Mask's Path\n</pre> In\u00a0[5]: Copied! <pre>fpar_aggregator.initMaskPath(mask_file_path)\n</pre> fpar_aggregator.initMaskPath(mask_file_path) <pre>Mask Summary:\n\nMask_path: crop mask/asap_mask_crop_v04.tif\nCRS: WGS 84\nExtent: BoundingBox(left=-180.004464285715, bottom=-56.00446430667502, right=179.99553577188502, top=75.004464285715)\nData Type: uint8\nNoData Value: None\nSpatial Resolution: (80640, 29346)\nPixel Size: (0.004464285715, 0.004464285715)\nMin/Max Value: (0, 100)\n\nMask Initialized Correctly, Initialize The Shapefile\n</pre> In\u00a0[6]: Copied! <pre>fpar_aggregator.initShapefilePath(shapefile_file_path)\n</pre> fpar_aggregator.initShapefilePath(shapefile_file_path) <pre>Shapefile Summary:\n\nGeometry Type: ['MultiPolygon' None 'Polygon']\nCoordinate Reference System (CRS): WGS 84\nExtent: [-180.          -55.7948999   180.           83.62741852]\nFeature Count: 2368\nAttributes: ['adm1_code', 'adm1_name', 'adm0_code', 'adm0_name', 'adm0_name_', 'adm1_name_', 'asap1_id', 'asap0_id', 'geometry']\n\nShapefile Initialized Correctly, You Can Check The Data Compatibility\n</pre> In\u00a0[7]: Copied! <pre>fpar_aggregator.DataCompatibility()\n</pre> fpar_aggregator.DataCompatibility() <pre>NO ISSUE: The pixel sizes of the mask and predictor are identical: (0.004464285715, 0.004464285715)\nNO ISSUE: The projections of the mask and predictor are identical: WGS 84\nNO ISSUE: The projections of the raster data and shapefile are identical: WGS 84\n\nCOMPATIBILITY CHECK PASSED: The data is compatible. No resolution or projection mismatches were detected.\n</pre> In\u00a0[8]: Copied! <pre>fpar_aggregator.fixCompatibilityIssues(rescale_factor=None, # None = Rescale OFF\n                                      resampling_method=\"bilinear\") # Defualt Bilinear\n</pre> fpar_aggregator.fixCompatibilityIssues(rescale_factor=None, # None = Rescale OFF                                       resampling_method=\"bilinear\") # Defualt Bilinear <pre>Checking for compatibility issues...\nNo compatibility issues detected. Predictor, mask, and shapefile are already compatible.\n</pre> In\u00a0[9]: Copied! <pre>fpar_aggregator.selectRegionOfInterest(selected_countries,\n                                      country_column_name)\n</pre> fpar_aggregator.selectRegionOfInterest(selected_countries,                                       country_column_name) <pre>Filtered shapefile saved to: shapefile/filtered_gaul1_asap.shp\nRegion of Interest (ROI) successfully selected based on the specified countries: Norway, Spain.\n</pre> In\u00a0[10]: Copied! <pre>%time fpar_aggregator.clipPredictor()\n</pre> %time fpar_aggregator.clipPredictor() <pre>Clipping the predictor data...\n</pre> <pre>Clipping Rasters: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:08&lt;00:00,  4.06s/it]</pre> <pre>Clipping operation successful with the Region of Interest (ROI).\nCPU times: total: 8.02 s\nWall time: 8.13 s\n</pre> <pre>\n</pre> <p>Note &amp; Caution: The Function is a multiprocessing process. Using the main shapefile without filtering may led to system crash or error due to the big amount of geometry objects in original shapefile.</p> In\u00a0[11]: Copied! <pre># Mask On\nuse_mask=True\ncalculation_mode=\"weighted_mean\"\nall_touched=False\n\n%time fpar_aggregator.runAggregation(use_mask, invalid_values, calculation_mode, all_touched)\n</pre> # Mask On use_mask=True calculation_mode=\"weighted_mean\" all_touched=False  %time fpar_aggregator.runAggregation(use_mask, invalid_values, calculation_mode, all_touched) <pre>Starting aggregation...\nStarting aggregation with the selected Region of Interest (ROI) for FPAR.\n</pre> <pre>Processing rasters: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:05&lt;00:00,  2.72s/raster]</pre> <pre>Aggregation complete. Data saved to Aggregated_FPAR.csv.\nCPU times: total: 5.92 s\nWall time: 5.9 s\n</pre> <pre>\n</pre> In\u00a0[12]: Copied! <pre># Mask Off\nuse_mask=False\ncalculation_mode=\"overall_mean\"\nall_touched=False\n\n%time fpar_aggregator.runParallelAggregation(use_mask, invalid_values, calculation_mode, all_touched)\n</pre> # Mask Off use_mask=False calculation_mode=\"overall_mean\" all_touched=False  %time fpar_aggregator.runParallelAggregation(use_mask, invalid_values, calculation_mode, all_touched) <pre>Starting aggregation...\nStarting aggregation with the selected Region of Interest (ROI) for FPAR.\n</pre> <pre>Processing rasters: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:02&lt;00:00,  1.33s/raster]</pre> <pre>Aggregation complete. Data saved to Aggregated_overall_mean_FPAR_20240315_162031.csv.\nCPU times: total: 422 ms\nWall time: 3.2 s\n</pre> <pre>\n</pre> In\u00a0[13]: Copied! <pre># Mask On\nuse_mask=True\ncalculation_mode=\"weighted_mean\"\nall_touched=False\n\n%time fpar_aggregator.runParallelAggregation(use_mask, invalid_values, calculation_mode, all_touched)\n</pre> # Mask On use_mask=True calculation_mode=\"weighted_mean\" all_touched=False  %time fpar_aggregator.runParallelAggregation(use_mask, invalid_values, calculation_mode, all_touched) <pre>Starting aggregation...\nStarting aggregation with the selected Region of Interest (ROI) for FPAR.\n</pre> <pre>Processing rasters: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:04&lt;00:00,  2.33s/raster]\n</pre> <pre>Aggregation complete. Data saved to Aggregated_weighted_mean_FPAR_20240315_162034.csv.\nCPU times: total: 422 ms\nWall time: 5.19 s\n</pre> <p>Caution: <code>runAggregation</code> and <code>runParallelAggregation</code> function combine clipping and aggregation, so it does not save clipped raster, if you did not clip.</p>"},{"location":"examples/intro/#welcom-to-earthstat","title":"Welcom to EarthStat\u00b6","text":"<p>Welcome to EarthStat, your comprehensive tool for extracting geographical and statistical data. This notebook is designed to guide you through the initial setup, data preparation, and the various functionalities available in the EarthStat library.</p>"},{"location":"examples/intro/#installation","title":"Installation\u00b6","text":""},{"location":"examples/intro/#user-configuration-for-extracting-statistical-info","title":"User Configuration For Extracting Statistical Info\u00b6","text":""},{"location":"examples/intro/#data-initialization","title":"Data initialization\u00b6","text":"<p>Set up the foundational paths for your data processing pipeline. This includes initializing the directory for the predictor data, the path for the mask file, and the location of the shapefile. Each step is crucial for ensuring that the subsequent data processing and analysis can proceed smoothly.</p>"},{"location":"examples/intro/#check-data-compatibility-and-fix-data-compatibility-issues","title":"Check Data Compatibility and Fix Data Compatibility Issues\u00b6","text":"<p>Evaluate the compatibility of projections and pixel sizes across the mask, raster, and shapefile to ensure seamless data integration. This check confirms that the projection systems align for the mask, raster, and shapefile, and it also verifies that the pixel sizes between the raster and mask are compatible.</p>"},{"location":"examples/intro/#resolving-data-compatibility-issues","title":"Resolving Data Compatibility Issues\u00b6","text":"<p>This section addresses how to rectify issues identified by the data compatibility check. It focuses on resolving mismatches in pixel size between the raster and mask, or discrepancies in the Coordinate Reference System (CRS) among the raster, mask, and shapefile. The objective is to ensure uniformity in scale, resolution, and geospatial alignment across all datasets involved in the analysis.</p> <p>Paramaters:</p> <ul> <li><code>rescale_factor</code>: This parameter allows for the adjustment of the data's scale. By default, it is set to <code>None</code>, maintaining the original scale of the data. To alter the scale, specify a new range with a tuple, such as <code>(0,100)</code>.</li> <li><code>resampling_method</code>: This specifies the technique used to resample the data, with options including <code>\"nearest\"</code>, <code>\"bilinear\"</code>, <code>\"cubic\"</code>, and <code>\"average\"</code>. The default method is <code>\"bilinear\"</code>, suitable for a wide range of applications.</li> </ul>"},{"location":"examples/intro/#selecting-region-of-interest-roi-filter-shapefile","title":"Selecting Region of Interest (ROI) - Filter Shapefile\u00b6","text":"<p>Specify the area for data analysis by identifying the region of interest. Configure the target ROI and link it to the corresponding column that designates country or area names within the dataset.</p>"},{"location":"examples/intro/#clipping-predictor-data","title":"Clipping Predictor Data\u00b6","text":"<p>Clip the predictor data to the boundaries defined in the main shapefile.</p>"},{"location":"examples/intro/#executing-data-aggregation","title":"Executing Data Aggregation\u00b6","text":"<p>Start data aggregation process, leveraging the predictor data, mask, and the filtered shapefile.</p>"},{"location":"examples/intro/#parameters","title":"Parameters\u00b6","text":"<ul> <li><p><code>use_mask</code> (bool): Specifies whether to apply a mask to the raster data. When set to <code>True</code>, the function will use the mask path provided (if applicable) to only process areas within the mask. Default is <code>False</code>.</p> </li> <li><p><code>invalid_values</code> (list of int): A list of pixel values to be treated as invalid and excluded from the aggregation. For example, <code>[255, 254, 251]</code> can be used to ignore certain values that represent no data or errors in the raster files.</p> </li> <li><p><code>calculation_mode</code> (str): Determines the mode of aggregation for pixel values. Supported modes include:</p> <ul> <li><code>\"overall_mean\"</code>: Calculates the mean of all valid pixel values across the raster dataset.</li> <li><code>\"weighted_mean\"</code>: Calculates the weighted mean of the valid pixel values using the mask values as weights. This mode is applicable only when <code>use_mask</code> is <code>True</code> and a valid <code>mask_path</code> is provided.</li> <li><code>\"filtered_mean\"</code>: Applies a filter using the validated mask values to mask the data before calculating the mean. This mode is intended for scenarios where only specific parts of the raster that meet certain conditions (defined by the mask) should contribute to the mean calculation.</li> </ul> </li> <li><p><code>all_touched</code> (bool): If set to <code>True</code>, all pixels touched by geometries will be included in the mask. If <code>False</code>, only pixels whose center is within the geometry or touching the geometry boundary will be included. Default is <code>False</code>.</p> </li> </ul>"},{"location":"examples/intro/#parallel-processing-with-runparallelaggregation","title":"Parallel Processing with <code>runParallelAggregation</code>\u00b6","text":"<p>The <code>runParallelAggregation</code> method is designed to process and aggregate raster data across multiple files in parallel, enhancing performance for large datasets. This method leverages multiple CPU cores to simultaneously process different portions of the data, reducing overall computation time.</p>"},{"location":"examples/xES/","title":"xES","text":"In\u00a0[\u00a0]: Copied! <pre># install the EarthStat\n\n!pip install earthstat\n</pre> # install the EarthStat  !pip install earthstat In\u00a0[\u00a0]: Copied! <pre># import the package\n\nfrom earthstat import xEarthStat as xES\n</pre> # import the package  from earthstat import xEarthStat as xES <p>Create an instance of xEarthStat, and initialize the workflow</p> In\u00a0[\u00a0]: Copied! <pre># create an instance of the workflow\n\nEU_AgERA5 = xES()\n</pre> # create an instance of the workflow  EU_AgERA5 = xES() <p>initilize the workflow by:</p> <ul> <li>ROI Name (<code>str</code>): Unique identifier for your ROI.</li> <li>shape_file_path (<code>str</code>): shapefile file path</li> </ul> In\u00a0[\u00a0]: Copied! <pre>ROI_name = 'EU'\nshape_file_path = 'EU.shp'\n\nEU_AgERA5.init_workflow(\n    ROI_name, \n    shape_file_path # Adding shape file path is optional\n)\n</pre> ROI_name = 'EU' shape_file_path = 'EU.shp'  EU_AgERA5.init_workflow(     ROI_name,      shape_file_path # Adding shape file path is optional ) <p>Note &amp; Caution: Adding shapefile(optional): for just downloading data without data aggregation you can pass the shapefile.</p> <p>Note &amp; Caution: Currently, xEarthStat can just download 7 variables included in the table below.</p> Variable AgERA5 Parameter Statistical Download Type Maximum Temperature 2m_temperature 24_hour_maximum Minimum Temperature 2m_temperature 24_hour_minimum Mean Temperature 2m_temperature 24_hour_mean Solar Radiation Flux solar_radiation_flux - Precipitation Flux precipitation_flux - Wind Speed 10m_wind_speed 24_hour_mean Vapour Pressure vapour_pressure 24_hour_mean <ul> <li>Bounding Box (<code>list</code> of <code>float</code>): <code>north</code>, <code>west</code>, <code>south</code>, and <code>east</code> coordinates of ROI.</li> <li>start_year (<code>int</code>): the start year for data.</li> <li>end_year (<code>int</code>):  the end year for data.</li> </ul> <p>Example: To download data from 2000 to 2020, set start_year to 2000 and end_year to 2020. For a single year, set both to the same year.</p> In\u00a0[\u00a0]: Copied! <pre># Define the AgERA5's variables to be downloaded\n\nAgERA5_parameters = [\n    'Maximum_Temperature', 'Minimum_Temperature', 'Mean_Temperature',\n    'Solar_Radiation_Flux', 'Precipitation_Flux', 'Wind_Speed','Vapour_Pressure'\n    ]\n\n# Define the ROI's bounding box, start year, and end year\n\nROI_bounding_box = [71, -31, 34.5, 40]  # [north, west, south, east]\nstart_year = 2000\nend_year = 2001\n</pre> # Define the AgERA5's variables to be downloaded  AgERA5_parameters = [     'Maximum_Temperature', 'Minimum_Temperature', 'Mean_Temperature',     'Solar_Radiation_Flux', 'Precipitation_Flux', 'Wind_Speed','Vapour_Pressure'     ]  # Define the ROI's bounding box, start year, and end year  ROI_bounding_box = [71, -31, 34.5, 40]  # [north, west, south, east] start_year = 2000 end_year = 2001 <p>Next, initialize the AgERA5 downloader by defined parameters:</p> In\u00a0[\u00a0]: Copied! <pre># Initialize the AgERA5 downloader\n\nEU_AgERA5.init_AgERA5_downloader(\n    AgERA5_parameters,\n    ROI_bounding_box,\n    start_year,\n    end_year\n)\n</pre> # Initialize the AgERA5 downloader  EU_AgERA5.init_AgERA5_downloader(     AgERA5_parameters,     ROI_bounding_box,     start_year,     end_year ) <p><code>xES.download_AgERA5</code> options:</p> <ul> <li><code>num_requests</code>: the number of downloading requests sends to CDS's API server until download all data.</li> <li><code>extract</code>: <code>True</code> to Extract the downloaded AgERA5 zip files, set <code>False</code> if you don't want to extract zip files.</li> </ul> In\u00a0[\u00a0]: Copied! <pre># Start downloading the AgERA5 data\n\nEU_AgERA5.download_AgERA5(num_requests=6,\n                          extract=True)\n</pre> # Start downloading the AgERA5 data  EU_AgERA5.download_AgERA5(num_requests=6,                           extract=True) <p>Note &amp; Caution:</p> <ul> <li>Don't send more than 5 requests to the server. That leads to the server to block your API key from downloading.</li> <li>If your ROI is to much small decrease the number of requests to two.</li> </ul> In\u00a0[\u00a0]: Copied! <pre># Explore the number of all CPU cores\n\nimport os\n\ncpu_cores = os.cpu_count()\n\nprint(f'Number of CPU cores: {cpu_cores}')\n</pre> # Explore the number of all CPU cores  import os  cpu_cores = os.cpu_count()  print(f'Number of CPU cores: {cpu_cores}') In\u00a0[\u00a0]: Copied! <pre># Start aggregating the downloaded AgERA5 data\n\nEU_AgERA5.Aggregate_AgERA5(\n\n    dataset_type = \"dekadal\",\n    all_touched=False,\n    stat='mean',\n    multi_processing=False,\n    max_workers=None, # None means using all CPU cores\n)\n</pre> # Start aggregating the downloaded AgERA5 data  EU_AgERA5.Aggregate_AgERA5(      dataset_type = \"dekadal\",     all_touched=False,     stat='mean',     multi_processing=False,     max_workers=None, # None means using all CPU cores ) In\u00a0[\u00a0]: Copied! <pre>EU_AgERA5.AgERA5_merged_csv(kelvin_to_celsius=False, \n                            output_name=None)\n</pre> EU_AgERA5.AgERA5_merged_csv(kelvin_to_celsius=False,                              output_name=None)"},{"location":"examples/xES/#welcom-to-xearthstat-for-agera5","title":"Welcom to xEarthStat For AgERA5\u00b6","text":"<p>xEarthStat for AgERA5 allows users to download and aggregate AgERA5 climate data for a specified Region of Interest (ROI). This document outlines the installation process, setup, and usage instructions to get you started.</p>"},{"location":"examples/xES/#installation","title":"Installation\u00b6","text":"<p>To use xEarthStat for AgERA5, you first need to install the <code>earthstat</code> Python package. Run the following command in your Python environment:</p>"},{"location":"examples/xES/#step-1install-import-xearthstat","title":"Step 1:Install &amp; Import xEarthStat\u00b6","text":""},{"location":"examples/xES/#step-2-initialize-xearthstat-workflow","title":"Step 2: Initialize xEarthStat Workflow\u00b6","text":""},{"location":"examples/xES/#step-3-download-agera5-from-cds","title":"Step 3: Download AgERA5 From CDS\u00b6","text":"<p>Download the AgERA5 data for your ROI by defining the following:</p> <ul> <li>AgERA5_parameters (<code>list</code>): Define the list of interested variables to download from CDS.</li> </ul>"},{"location":"examples/xES/#step-4-aggregate-data","title":"Step 4: Aggregate Data\u00b6","text":"<p>xEarthStat's Aggregation process utilize the availability of GPU for parallel computation, and using the avilalble CPU cores for multiprocessing. it automatically detect if there is a GPU or not, if not it shift computational processing on CPU.</p> <p><code>xES.Aggregate_AgERA5</code>:</p> <ul> <li><p><code>dataset_type</code>: Chosing the type of dataset, <code>dekadal</code> for aggregated dekadal (1,11,21 of month) dataset, <code>daily</code> for daily dataset.</p> </li> <li><p><code>all_touched</code>: Default to <code>False</code> to just consider pixels within the geometry object. <code>True</code> to consider all touched pixels by geo-object.</p> </li> <li><p><code>stat</code>:  <code>\"mean\"</code>(Default), <code>\"median\"</code>, <code>\"min\"</code>, <code>\"max\"</code>, <code>\"sum\"</code>.</p> </li> <li><p><code>multi_processing</code>: Enables parallel processing.</p> </li> <li><p><code>max_workers</code>: Default to total number of CPU's cores. You can change the number of cores that used in multiprocessing.</p> </li> </ul>"},{"location":"examples/xES/#step-5-optional-merge-aggregated-agera5s-variables-csvs","title":"Step 5 (Optional): Merge Aggregated AgERA5's Variables CSVs\u00b6","text":"<p>Optionally, merge all generated datasets' csv files into one merged csv for all aggregated variables:</p> <p><code>xES.AgERA5_merged_csv</code>:</p> <ul> <li><p><code>kelvin_to_celsius</code>: To convert the temperature unit from kelvin to celsius.</p> </li> <li><p><code>output_name</code>: option to add the name of merged csv, it's default to <code>AgERA5_{ROI_name}_merged_parameters_{workflow}_{timestamp}.csv</code></p> </li> </ul>"},{"location":"usage/main_usage/","title":"EarthStat Main Workflow Usage","text":"<p>EarthStat is a powerful tool for geospatial data processing and analysis. Below is a guide to the main workflow of EarthStat, including initialization, configuration, data processing, and aggregation.</p>"},{"location":"usage/main_usage/#initializing-the-library","title":"Initializing the Library","text":"<p>Import the library using:</p> <pre><code>from earthstat import EarthStat\n</code></pre>"},{"location":"usage/main_usage/#main-configuration-setup","title":"Main Configuration Setup","text":"<p>Initialize the core settings:</p> <p><code>predictor_name</code>: The name of the predictor being used. <code>predictor_dir</code>: The directory where the predictor's related files are stored. <code>mask_file_path</code>: The file path to the mask file, used for calculate weighted mean or mask the raster. <code>shapefile_file_path</code>: Path to the shapefile containing geographical boundaries. <code>selected_countries</code>: A list of countries - Region of interest (ROI). <code>country_column_name</code>: The column's name in the dataset that contains country names. <code>invalid_values</code>: A list of values considered invalid within the dataset.</p> <p>Important: Be sure to set <code>invalid_values</code> to <code>None</code> if you do not wish to exclude unprocessed values from the dataset.</p> <pre><code>predictor_name              = 'FPAR'\npredictor_dir               = 'FPAR_Data'\nmask_file_path              = 'crop_mask/Percent_Maize.tif'\nshapefile_file_path         = 'shapefile/gaul1_asap.shp'\ninterested_ROI              = [\"Norway\", \"Spain\"] \ncountry_column_name         = 'adm0_name' \ninvalid_values              =[255, 254, 251] # None-&gt; No Invalid Values\n</code></pre> <p>Caution: An increase in ROI size may lead to system crashes due to insuffienct RAM size, if you will not do parallel aggregation.</p>"},{"location":"usage/main_usage/#initialize-the-earthstat-object","title":"Initialize the EarthStat object","text":"<pre><code>fpar_aggregator = EarthStat(predictor_name)\n</code></pre>"},{"location":"usage/main_usage/#initialize-predictordata-directory-mask-and-shapefile-path","title":"Initialize Predictor/Data Directory, Mask, and Shapefile Path","text":"<p>Set up the foundational paths for your data processing pipeline. This includes initializing the directory for the predictor data, the path for the mask file, and the location of the shapefile. Each step is crucial for ensuring that the subsequent data processing and analysis can proceed smoothly.</p> <p>Example Usage:</p> <pre><code># Initialize the predictor data directory\nfpar_aggregator.initDataDir(predictor_dir)\n\n# Set the path for the mask file\nfpar_aggregator.initMaskPath(mask_file_path)\n\n# Define the location of the shapefile\nfpar_aggregator.initShapefilePath(shapefile_file_path)\n</code></pre>"},{"location":"usage/main_usage/#checking-data-compatibility","title":"Checking Data Compatibility","text":"<p>Evaluate the compatibility of projections and pixel sizes across the mask, raster, and shapefile to ensure seamless data integration. This check confirms that the projection systems align for the mask, raster, and shapefile, and it also verifies that the pixel sizes between the raster and mask are compatible.</p> <pre><code>fpar_aggregator.DataCompatibility()\n</code></pre>"},{"location":"usage/main_usage/#resolving-data-compatibility-issues","title":"Resolving Data Compatibility Issues","text":"<p>This section addresses how to rectify issues identified by the data compatibility check. It focuses on resolving mismatches in pixel size between the raster and mask, or discrepancies in the Coordinate Reference System (CRS) among the raster, mask, and shapefile. The objective is to ensure uniformity in scale, resolution, and geospatial alignment across all datasets involved in the analysis.</p> <ul> <li><code>rescale_factor</code>: This parameter allows for the adjustment of the data's scale. By default, it is set to <code>None</code>, maintaining the original scale of the data. To alter the scale, specify a new range with a tuple, such as <code>(0,100)</code>.</li> <li><code>resampling_method</code>: This specifies the technique used to resample the data, with options including <code>\"nearest\"</code>, <code>\"bilinear\"</code>, <code>\"cubic\"</code>, and <code>\"average\"</code>. The default method is <code>\"bilinear\"</code>, suitable for a wide range of applications.</li> </ul> <p>Example usage:</p> <pre><code># Disable rescaling and use default bilinear resampling\nfpar_aggregator.fixCompatibilityIssues(rescale_factor=None, resampling_method=\"bilinear\")\n\n# Rescale data to a new range (0, 100) and use default bilinear resampling\nfpar_aggregator.fixCompatibilityIssues(rescale_factor=(0,100), resampling_method=\"bilinear\")\n</code></pre>"},{"location":"usage/main_usage/#selecting-region-of-interest-roi","title":"Selecting Region of Interest (ROI)","text":"<p>Specify the area for data analysis by identifying the region of interest. Configure the target ROI and link it to the corresponding column that designates country or area names within the dataset.</p> <pre><code>fpar_aggregator.selectRegionOfInterest(interested_ROI,\n                                      country_column_name)\n</code></pre>"},{"location":"usage/main_usage/#clipping-predictor-data","title":"Clipping Predictor Data","text":"<p>Clip the predictor data to the boundaries defined in a shapefile. If no specific Region of Interest (ROI) is selected by the previous function, the entire area within the main shapefile (Not filtered shapefile) will be used for clipping. <pre><code>fpar_aggregator.clipPredictor()\n</code></pre></p> <p>Note &amp; Caution: The Function is a multiprocessing process. Using the main shapefile without filtering may led to system crash or error due to the big amount of geometry objects in original shapefile.</p>"},{"location":"usage/main_usage/#executing-data-aggregation","title":"Executing Data Aggregation","text":"<p>Start data aggregation process, leveraging the clipped predictor data, resampled mask, and the filtered shapefile.</p>"},{"location":"usage/main_usage/#parameters","title":"Parameters","text":"<ul> <li> <p><code>use_mask</code> (bool): Specifies whether to apply a mask to the raster data. When set to <code>True</code>, the function will use the mask path provided (if applicable) to only process areas within the mask. Default is <code>False</code>.</p> </li> <li> <p><code>invalid_values</code> (list of int): A list of pixel values to be treated as invalid and excluded from the aggregation. For example, <code>[255, 254, 251]</code> can be used to ignore certain values that represent no data or errors in the raster files.</p> </li> <li> <p><code>calculation_mode</code> (str): Determines the mode of aggregation for pixel values. Supported modes include:</p> </li> <li><code>\"overall_mean\"</code>: Calculates the mean of all valid pixel values across the raster dataset.</li> <li><code>\"weighted_mean\"</code>: Calculates the weighted mean of the valid pixel values using the mask values as weights. This mode is applicable only when <code>use_mask</code> is <code>True</code> and a valid <code>mask_file_path</code> is provided.</li> <li> <p><code>\"filtered_mean\"</code>: Applies a filter using the validated mask values to mask the data before calculating the mean. This mode is intended for scenarios where only specific parts of the raster that meet certain conditions (defined by the mask) should contribute to the mean calculation.</p> </li> <li> <p><code>all_touched</code> (bool): If set to <code>True</code>, all pixels touched by geometries will be included in the mask. If <code>False</code>, only pixels whose center is within the geometry or touching the geometry boundary will be included. Default is <code>False</code>.</p> </li> </ul> <p>Usage Example:</p> <p>The following example demonstrates how to use <code>runAggregation</code> to process raster data without applying a mask, excluding specific invalid pixel values, calculating the overall mean of the valid pixels, and considering only pixels whose center is within the geometry:</p> <p><pre><code># Without Mask \nuse_mask=False # True to use mask \ncalculation_mode=\"overall_mean\" # Options: weighted_mean, filtered_mean\nall_touched=False\n\nfpar_aggregator.runAggregation(use_mask, invalid_values, calculation_mode, all_touched)\n</code></pre> In this example, it processes raster data by applying a mask, excluding defined invalid values and the values out of intersect between them, calculating the weighted mean using the mask values as weights values.</p> <p><pre><code># With Mask\nuse_mask=True\ncalculation_mode=\"weighted_mean\"\nall_touched=False\n\nfpar_aggregator.runAggregation(use_mask, invalid_values, calculation_mode, all_touched)\n</code></pre> The last option is applying a mask to exclude the defined invalid values with the values out of intersect between raster and mask, calculating the overall mean.</p> <pre><code># With Mask\nuse_mask=True\ncalculation_mode=\"filtered_mean\"\nall_touched=False\n\nfpar_aggregator.runAggregation(use_mask, invalid_values, calculation_mode, all_touched)\n</code></pre>"},{"location":"usage/main_usage/#parallel-processing-with-runparallelaggregation","title":"Parallel Processing with <code>runParallelAggregation</code>","text":"<p>The <code>runParallelAggregation</code> method is designed to process and aggregate raster data across multiple files in parallel, enhancing performance for large datasets. This method leverages multiple CPU cores to simultaneously process different portions of the data, reducing overall computation time.</p> <p>Usage Example:</p> <p>It follows the same structure of <code>runAggregation</code> and the same parameters. <pre><code># Without Mask \nuse_mask=False # True to use mask \ncalculation_mode=\"overall_mean\" # Options: weighted_mean, filtered_mean\nall_touched=False\n\nfpar_aggregator.runParallelAggregation(use_mask, invalid_values, calculation_mode, all_touched)\n</code></pre></p>"},{"location":"usage/xES_usage/","title":"xEarthStat for AgERA5 Usage","text":"<p>xEarthStat for AgERA5 allows users to download and aggregate AgERA5 climate data for a specified Region of Interest (ROI). This document outlines the installation process, setup, and usage instructions to get you started.</p>"},{"location":"usage/xES_usage/#installation","title":"Installation","text":"<p>To use xEarthStat for AgERA5, you first need to install the <code>earthstat</code> Python package. Run the following command in your Python environment:</p> <pre><code>pip install earthstat\n</code></pre>"},{"location":"usage/xES_usage/#getting-started","title":"Getting Started","text":"<p>After installing the <code>earthstat</code> package, you can start using xEarthStat to download and aggregate data for your ROI. Here's a step-by-step guide:</p>"},{"location":"usage/xES_usage/#step-1-import-xearthstat","title":"Step 1: Import xEarthStat","text":"<pre><code>from earthstat import xEarthStat as xES\n</code></pre>"},{"location":"usage/xES_usage/#step-2-define-your-region-of-interest-roi","title":"Step 2: Define Your Region of Interest (ROI)","text":"<p>Specify your ROI's name, bounding box, and the time range for the data you're interested in:</p> <ul> <li>ROI Name (<code>str</code>): Unique identifier for your ROI.</li> <li>Bounding Box (<code>list</code> of <code>float</code>): Define the north, west, south, and east coordinates of your ROI.</li> <li>Time Range (<code>int</code>): Specify the start and end years.</li> </ul> <p>Example:</p> <pre><code>ROI_name = 'EU_AgERA5'\nstart_year = 2000\nend_year = 2001\nROI_bounding_box = [71, -31, 34.5, 40]  # Format: [north, west, south, east]\n</code></pre>"},{"location":"usage/xES_usage/#step-3-set-agera5-parameters","title":"Step 3: Set AgERA5 Parameters","text":"<p>List the climate parameters you want to download for your ROI:</p> <pre><code>AgERA5_parameters = [\n    'Maximum_Temperature', 'Minimum_Temperature', 'Mean_Temperature',\n    'Solar_Radiation_Flux', 'Precipitation_Flux', 'Wind_Speed', 'Vapour_Pressure'\n]\n</code></pre> <p>Note &amp; Caution: xEarthStat can just download 7 variables included in the table below.</p> Variable AgERA5 Parameter Statistical Download Type Maximum Temperature 2m_temperature 24_hour_maximum Minimum Temperature 2m_temperature 24_hour_minimum Mean Temperature 2m_temperature 24_hour_mean Solar Radiation Flux solar_radiation_flux - Precipitation Flux precipitation_flux - Wind Speed 10m_wind_speed 24_hour_mean Vapour Pressure vapour_pressure 24_hour_mean"},{"location":"usage/xES_usage/#step-4-define-the-shapefile-path","title":"Step 4: Define the Shapefile Path","text":"<p>Provide the file path to your shapefile:</p> <pre><code>shapefile_file_path = 'EU/admin_3.shp'\n</code></pre>"},{"location":"usage/xES_usage/#step-5-initialize-xearthstat","title":"Step 5: Initialize xEarthStat","text":"<p>Create an instance of xEarthStat with the specified parameters: - <code>workflow</code>: The type of final generated dataset, <code>dekadal</code> for aggregated dekadal (1,11,21 of month) dataset, <code>daily</code> for daily dataset.  - <code>multi_processing</code>: Enables parallel processing.</p> <pre><code>EU_AgERA5 = xES(ROI_name,\n                AgERA5_parameters,\n                start_year,\n                end_year,\n                ROI_bounding_box,\n                shapefile_path=shapefile_file_path,\n                workflow='daily',\n                multi_processing=True)\n</code></pre>"},{"location":"usage/xES_usage/#step-6-download-data","title":"Step 6: Download Data","text":"<p>Download the AgERA5 data for your ROI: - <code>num_requests</code>: the number of downloading requests sends to CDS's API server until download all data. - <code>extract</code>: Extract the downloaded AgERA5 zip files, set <code>False</code> if you don't want to extract them.</p> <pre><code>EU_AgERA5.download_AgERA5(num_requests=6, \n                          extract=True)\n</code></pre> <p>Note &amp; Caution: Don't send more than 6 requests to the server. That may lead to pressure on the server and may result in blocking your API key from downloading.</p>"},{"location":"usage/xES_usage/#step-7-aggregate-data","title":"Step 7: Aggregate Data","text":"<p>xEarthStat's Aggregation process utilize the availability of GPU for parallel computation, and using the avilalble CPU cores for multiprocessing. it automatically detect if there is a GPU or not, if not it shift computational processing on CPU.</p> <ul> <li><code>max_workers</code>: Default to total number of CPU's cores. You can change the number of cores that used in multiprocessing.</li> <li><code>all_touched</code>: Default to <code>False</code> to just consider pixels within the geometry object. <code>True</code> to consider all touched pixels by geo-object. </li> <li><code>stat</code>: Default to <code>\"mean\"</code> to calculate the mean. There are other options, <code>\"median\"</code>, <code>\"min\"</code>, <code>\"max\"</code>, and <code>\"sum\"</code>.</li> </ul> <pre><code>import os\ncpu_cores = os.cpu_count()  # Get the number of all CPU cores\nprint(f'Number of CPU cores: {cpu_cores}')\n\nEU_AgERA5.Aggregate_AgERA5(max_workers=cpu_cores, all_touched=False, stat='mean')\n</code></pre>"},{"location":"usage/xES_usage/#step-8-export-aggregated-data","title":"Step 8: Export Aggregated Data","text":"<p>Optionally, merge all generated datasets' csv files into one merged csv for all aggregated variables: - <code>kelvin_to_celsius</code>: To convert the temperature unit from kelvin to celsius. - <code>output_name</code>: option to add the name of merged csv, it's default to <code>AgERA5_{ROI_name}_merged_parameters_{workflow}_{timestamp}.csv</code></p> <pre><code>EU_AgERA5.AgERA5_merged_csv(kelvin_to_celsius=False, \n                            output_name=None)\n</code></pre>"}]}